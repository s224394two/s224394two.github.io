[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "What is the cause of the increase in UFO sightings?",
    "section": "",
    "text": "Since the beginning of the 20th century we have reported UFO sightings. What this project is trying to do is to look at the trend of the UFO sightings and try to explain them in a way which is not attributed to an increase in actual UFOs. Since a major part of the sightings are in the US (which already indicates that something weird is up) we are only focusing on that part of the data.\n\nUFO sightings over time\nThe first thing we want to examine is the trend of UFO sightings over the years. We choose to look at only the sightings from 1990 and further since the number of sightings is fairly low up until that point and therefore there is no meaningful insight to gain. We also look at the particular shapes of sighings and lastly we plotted some important UFO related media too see if they might contribute to the increase.\n\n\nCode\nimport pandas as pd\nfrom bokeh.plotting import figure, show\nfrom bokeh.io import output_notebook\nfrom bokeh.models import ColumnDataSource, HoverTool, LabelSet\nfrom bokeh.palettes import Category20\n\n# Render inline\noutput_notebook(hide_banner=True)\n\n# === Load & preprocess ===\ndata = pd.read_csv(\"data/complete.csv\", on_bad_lines='skip')\ndata[\"datetime\"] = pd.to_datetime(data[\"datetime\"], errors=\"coerce\")\ndf = (\n    data[data[\"country\"].str.lower() == \"us\"]\n    .dropna(subset=[\"datetime\", \"shape\"])\n    .copy()\n)\ndf[\"year\"] = df[\"datetime\"].dt.year\n\n# === Totals from 1990‚Äì2014 ===\ntotals = df.groupby(\"year\").size()\ntotals = totals[(totals.index &gt;= 1990) & (totals.index &lt;= 2014)]\n\n# === Shape pivot from 1990‚Äì2014 ===\nshape_counts_all = df.groupby([\"year\", \"shape\"]).size().unstack(fill_value=0)\nshape_counts_all = shape_counts_all[\n    (shape_counts_all.index &gt;= 1990) &\n    (shape_counts_all.index &lt;= 2014)\n]\n\n# === Top 5 shapes + ‚Äúuncommon shapes‚Äù ===\nshape_totals = shape_counts_all.sum().sort_values(ascending=False)\ntop_shapes    = shape_totals.head(5).index\nother_shapes  = shape_totals.index.difference(top_shapes)\n\nshape_counts = shape_counts_all[top_shapes].copy()\nshape_counts[\"uncommon shapes\"] = shape_counts_all[other_shapes].sum(axis=1)\n\n# === Prepare ColumnDataSource ===\nfinal_shapes = [\"uncommon shapes\"] + list(top_shapes)\nsource_data  = {\"year\": shape_counts.index.tolist()}\n#colors       = Category20[20][:len(final_shapes)]\ncolors = [\n    \"#f0ad4e\",  # yellow  ‚Üí \"uncommon shapes\"\n    \"#007bff\",  # blue    ‚Üí top shape 1\n    \"#fd7e14\",  # orange  ‚Üí top shape 2\n    \"#6f42c1\",  # purple  ‚Üí top shape 3\n    \"#d9534f\",   # red     ‚Üí top shape 5\n    \"#4bbf73\"  # green    ‚Üí top shape 4\n    \n]\nfor s in final_shapes:\n    source_data[s] = shape_counts[s].values\nsource = ColumnDataSource(source_data)\n\n# === Emoji map ===\nemoji_map = {\n    \"light\": \"üí°\", \"triangle\": \"üî∫\", \"circle\": \"‚≠ï\",\n    \"fireball\": \"üî•\", \"unknown\": \"‚ùì\", \"uncommon shapes\": \"üõ∏\"\n}\n\n# === Media events 1990‚Äì2014 ===\nmedia = {\n    1951: \"The Day the Earth Stood Still\",\n    1977: \"Close Encounters\", 1979: \"Alien\", 1982: \"E.T.\",\n    1986: \"Aliens\", 1993: \"The X-Files (TV)\", 1996: \"Independence Day\",\n    1998: \"X-Files: The Movie\", 2002: \"Signs\",\n    2009: \"District 9\", 2014: \"Edge of Tomorrow\"\n}\nmedia_years = [y for y in media if 1990 &lt;= y &lt;= 2014 and y in totals.index]\nmedia_source = ColumnDataSource(dict(\n    year =[y for y in media_years],\n    count=[totals[y] for y in media_years],\n    title=[media[y] for y in media_years]\n))\n\n# === Figure setup ===\np = figure(\n    width=640, height=400,\n    x_range=(1990, 2014),\n    y_range=(0, shape_counts.sum(axis=1).max() * 1.15),\n    background_fill_color=\"#f5f5f5\",\n    title=\"U.S. UFO Shape Distribution Over Time (1990‚Äì2014)\",\n    tools=\"\", toolbar_location=None\n)\n\n# === Stacked area ===\np.varea_stack(\n    stackers=final_shapes,\n    x=\"year\",\n    color=colors,\n    legend_label=[f\"{emoji_map[s]} {s}\" for s in final_shapes],\n    source=source\n)\np.legend.items = list(reversed(p.legend.items))\n\n# === Media event markers ===\nmedia_renderer = p.circle(\n    'year','count', source=media_source,\n    size=12, fill_color=\"#ffd700\", line_color=\"white\",\n    line_width=1.3, legend_label=\"Media Event\", level=\"overlay\"\n)\np.add_tools(HoverTool(\n    renderers=[media_renderer],\n    tooltips=[(\"Movie\", \"@title\"), (\"Year\",\"@year\"), (\"Sightings\",\"@count\")],\n    mode=\"mouse\", point_policy=\"follow_mouse\"\n))\n\n# === Emojis ===\nrecent = shape_counts.tail(25)\nmax_h  = recent.sum(axis=1).max()\nx_pts, y_pts, emojis, sizes = [], [], [], []\nfor i, s in enumerate(final_shapes):\n    yr    = recent[s].idxmax()\n    below = recent[final_shapes[:i]].loc[yr].sum()\n    band  = recent[s].loc[yr]\n    x_pts.append(yr)\n    y_pts.append(below + band/2)\n    emojis.append(emoji_map[s])\n    sizes.append(f\"{10 + band/max_h*16 - 4:.0f}pt\")\n\nemoji_source = ColumnDataSource(dict(x=x_pts, y=y_pts, emoji=emojis, size=sizes))\np.add_layout(LabelSet(\n    x='x', y='y', text='emoji', source=emoji_source,\n    text_font_size='size', text_align=\"center\", text_baseline=\"middle\"\n))\n\n# === Styling ===\np.xaxis.axis_label            = \"Year\"\np.yaxis.axis_label            = \"Sightings\"\np.xaxis.major_label_text_color = \"#000\"\np.yaxis.major_label_text_color = \"#000\"\np.xaxis.axis_line_color       = \"#000\"\np.yaxis.axis_line_color       = \"#000\"\np.xgrid.grid_line_color       = None\np.ygrid.grid_line_color       = \"#222244\"\np.title.text_color            = \"#000\"\np.title.text_font_size        = \"12pt\"\np.legend.label_text_color     = \"#000000\"\np.legend.background_fill_alpha=  1\np.legend.location             = \"top_left\"\np.legend.label_text_font_size = \"9pt\"\n\n# Show it\nshow(p)\n\n\n\n\n\n\n  \n\n\n\n\n\nFigure 1: Times series plot which shows the distribution of the different shapes and sightings, but also highlights some important dates in regards to UFO-related media releases. There has been a rather large increase over the year. In particular after the release of ‚Äúindependence day‚Äù and the the show x-files.\nTo more clearly see the distribution of the different shapes over the years we also look at a pie-chart.\n\n\nCode\nfrom bokeh.io import output_notebook, show\nfrom bokeh.plotting import figure\nfrom bokeh.models import ColumnDataSource, Slider, CustomJS, Div\nfrom bokeh.layouts import column, row\nimport pandas as pd\nimport numpy as np\nfrom math import pi, cos, sin\n\noutput_notebook(hide_banner=1)\n\n# === Load and preprocess data ===\ndf = pd.read_csv('data/complete.csv', on_bad_lines='skip', dtype=str)\ndf['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')\ndf = df.dropna(subset=['datetime'])\ndf['year'] = df['datetime'].dt.year.astype(int)\ndf['shape'] = df['shape'].fillna('UNKNOWN').str.upper()\ndf = df[(df['year'] &gt;= 1990) & (df['year'] &lt;= 2014)]\ndf = df[df['shape'] != 'OTHER']  # ‚úÖ REMOVE \"OTHER\" COMPLETELY\n\n# === Determine top shapes ===\nyears = list(range(1990, 2015))\ntop_shapes = set()\nfor y in years:\n    excluded_shapes = {'CIGAR', 'FORMATION',\"RECTANGLE\"}\n    cnts = df[(df['year'] == y) & (~df['shape'].isin(excluded_shapes))]['shape'].value_counts()\n    top_shapes |= set(cnts.index[:7])\ntop_shapes = sorted(top_shapes)\n\n# === Emoji & Color Map ===\nemoji_map = {\n    'CIRCLE': '‚≠ï',\n    'DISK': 'üíø',\n    'FIREBALL': 'üî•',\n    'LIGHT': 'üí°',\n    'OVAL': 'ü•ö',\n    'SPHERE': 'üîµ',\n    'TRIANGLE': 'üî∫',\n    'UNKNOWN': '‚ùì',\n    'Uncommon Shapes': 'üõ∏'\n}\n\n# ‚úÖ MANUAL COLOR ASSIGNMENT (customize here)\ncolor_map = {\n    'CIRCLE': \"#6610f2\",\n    'DISK': \"#1f9bcf\",\n    'FIREBALL': \"#d9534f\",\n    'LIGHT': \"#007bff\",\n    'OVAL': \"#6f42c1\",\n    'SPHERE': \"#20c997\",\n    'TRIANGLE': \"#fd7e14\",\n    'UNKNOWN': \"#4bbf73\",\n    'Uncommon Shapes': \"#f0ad4e\"\n}\n\n# === Prepare data per year ===\ndata_by_year = {}\nfor y in years:\n    cnts = df[df['year'] == y]['shape'].value_counts()\n    top7 = cnts.iloc[:7]\n    uncommon = cnts.iloc[7:].sum()\n    labels = list(top7.index)\n    values = list(top7.values)\n    if uncommon &gt; 0:\n        labels.append('Uncommon Shapes')\n        values.append(uncommon)\n    total = sum(values)\n\n    angles = [v / total * 2 * pi for v in values]\n    starts = np.cumsum([0] + angles[:-1])\n    ends = starts + angles\n    mids = starts + np.array(angles) / 2\n\n    x_inner = 0.6 * np.cos(mids)\n    y_inner = 1 + 0.6 * np.sin(mids)\n\n    pct_vals = [v / total * 100 for v in values]\n    emoji_pct = [\n        f\"{emoji_map.get(lbl, '')}\\n{p:.1f}%\" if p &gt;= 10 else f\"{emoji_map.get(lbl, '')}\"\n        for lbl, p in zip(labels, pct_vals)\n    ]\n\n    data_by_year[str(y)] = {\n        'start_angle': starts.tolist(),\n        'end_angle': ends.tolist(),\n        'color': [color_map.get(lbl, \"#cccccc\") for lbl in labels],\n        'emoji_pct': emoji_pct,\n        'x_inner': x_inner.tolist(),\n        'y_inner': y_inner.tolist(),\n        'label': labels\n    }\n\n# === Initial Year Setup ===\ninitial = years[0]\nsrc = ColumnDataSource(data_by_year[str(initial)])\n\n# === Figure ===\np = figure(height=460, width=458,\n           title=f\"UFO Shapes in {initial}\",\n           toolbar_location=None,\n           x_range=(-1.2, 1.2), y_range=(0, 2.4),background_fill_color=\"#f5f5f5\")\n\np.wedge(x=0, y=1, radius=0.9,\n        start_angle='start_angle', end_angle='end_angle',\n        fill_color='color', line_color='white',\n        source=src)\n\np.text(x='x_inner', y='y_inner', text='emoji_pct',\n       source=src,\n       text_align='center', text_baseline='middle',\n       text_font_size='12pt')\n\np.axis.visible = False\np.grid.visible = False\np.xaxis.axis_line_color= \"#333333\"\n# === Slider ===\nslider = Slider(start=years[0], end=years[-1], value=initial, step=1, title=\"Year\")\n\ncallback = CustomJS(args=dict(src=src, data_by_year=data_by_year, plot=p, slider=slider), code=\"\"\"\n    const yr = slider.value.toString();\n    const d = data_by_year[yr];\n    src.data = d;\n    plot.title.text = 'UFO Shapes in ' + yr;\n    src.change.emit();\n\"\"\")\nslider.js_on_change('value', callback)\n\n# === Legend as HTML (aligned beside the chart) ===\nlegend_html = \"&lt;div style='font-size: 14px; line-height: 1.6em;'&gt;\"\nfor shape in top_shapes + ['Uncommon Shapes']:\n    emoji = emoji_map.get(shape, '')\n    color = color_map.get(shape, '#999999')\n    label = shape.lower()\n    legend_html += f\"\"\"\n        &lt;div style=\"display: flex; align-items: center; gap: 8px; margin-bottom: 6px;\"&gt;\n            &lt;div style=\"width: 14px; height: 14px; background-color: {color}; border-radius: 3px; flex-shrink: 0;\"&gt;&lt;/div&gt;\n            &lt;span&gt;{emoji} {label}&lt;/span&gt;\n        &lt;/div&gt;\n    \"\"\"\nlegend_html += \"&lt;/div&gt;\"\nlegend_div = Div(text=f\"&lt;div style='margin-left:20px; margin-top:30px'&gt;{legend_html}&lt;/div&gt;\", width=160)\n\n# === Layout ===\nlayout = column(slider, row(p, legend_div))\nshow(layout)\n\n\n\n  \n\n\n\nFigure 2: The pie-chart shows the different shapes of the reported UFOs. ‚ÄúUncommon shapes‚Äù refers to the sum of all the different shapes which are to few to be their own category and is therefore often the biggest category. The real biggest category is light. This makes one suspect that a lot of the sightings may be from air craft at night.\nThe time-series plot above illustrates the number of reported UFO sightings in the United States from 1990 to 2014. Overall, there is a clear upward trend in the number of sightings over the years, peaking around 2012‚Äì2013. Notably, a sharp decline in sightings is observed after 2013. This drop is not necessarily indicative of a real-world change in UFO activity, but rather reflects the structure of the dataset, which ends around mid-September 2013. Thus, the apparent decline is primarily due to incomplete data.\nThe peak around 2012‚Äì2013 may be attributed to a combination of cultural and technological factors. According to an article in Astronomy titled ‚ÄúReports of rising UFO sightings are greatly exaggerated,‚Äù the widespread use of smartphone cameras without mechanical shutters may introduce image artifacts, such as blurring and smearing, which could contribute to mistaken sightings. Additionally, the ‚Äú2012 phenomenon‚Äù a widely circulated belief that the year 2012 would mark a significant transformation or apocalyptic event may have heightened public sensitivity and made individuals more prone to misinterpret ordinary visual stimuli as extraordinary.\nThe plot also includes a frequency distribution of reported UFO shapes between 1990 and 2014. While most shapes appear consistently reported over time, there is a noticeable spike in reports of ‚Äúunknown‚Äù shapes around 1995. This anomaly suggests a temporary increase in sightings where witnesses were unable or unwilling to classify the object‚Äôs form, possibly due to ambiguity in observations or growing public discourse about UFOs during that period.\nTo understand the broader pattern of increasing sightings from the 1990s to the early 2010s, one must consider external societal trends. Data from the International Civil Aviation Organization (ICAO)International Civil Aviation Organization (n.d.) suggest a steady increase in global air traffic, as indicated by rising Revenue Passenger-Kilometres (RPKs). Although the data do not directly reflect the number of flights, they imply a growing presence of aerial vehicles in the skies, which may increase the likelihood of misidentifying conventional aircraft as unidentified flying objects.\nAdditionally, the influence of pop culture is clearly visible. Markers on the time-series plot indicate the release of major alien-themed media, such as The X-Files and Independence Day. These releases coincide with noticeable spikes in UFO sightings, suggesting that media exposure may influence public perception and increase observational activity. This idea is supported by a CBC article titled ‚ÄúRecord British UFO sightings in 1990s‚Äù CBC News (2009) which asserts that such media events raise public awareness and curiosity, leading to more frequent UFO reports.\n\n\nNumber of sightings per hour\nWhat happens when we shift our focus to when these sightings occur throughout the day?\n\n\nCode\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndata = pd.read_csv(\"data/complete.csv\", on_bad_lines='skip')\ndata['datetime'] = pd.to_datetime(data['datetime'], errors='coerce')\ndf=data[data[\"country\"]==\"us\"].sort_index(level=\"datetime\")\ndf = df.dropna(subset=['datetime'])\ndf = df.sort_values(by='datetime').reset_index(drop=True)\ndf=df.dropna()\n\nplt.figure().set_figwidth(7)\nplt.title(\"Number of sightings per hour \")\nax=plt.gca()\nplt.xticks(np.arange(0, 25, 1))\nax.set_facecolor(\"#f5f5f5\")\n\n\n#ax.xaxis.grid(False)\n#ax.grid(True,axis=\"y\", zorder=1)\nhourtime=df[\"time\"]=df[\"datetime\"].dt.hour\nplt.hist(hourtime, bins=24, range=(0, 24), density=0, color='#007bff',zorder=4)\nax.grid(True, axis=\"y\",linestyle='-', alpha=0.7,color=\"#222244\",zorder=0)\nplt.xlim(0,24)\nplt.xlabel('Hour of the Day')\nplt.ylabel(\"Population\")\nplt.show()\n\n\n\n\n\n\n\n\n\nFigure 3: This figure shows the the number of sightings per hour. It is clear that the sightings are mostly a thing of the evening/night. This also makes sense considering that a lot of the sightings are light.\nAs shown in Figure 3, the majority of sightings are clustered between 20:00 and 24:00, with a noticeable peak at 22:00. Several factors might account for this trend. Referring back to Figure 2, we see that the most commonly reported UFO shape is simply described as ‚Äúlight.‚Äù This aligns neatly with what we might expect after all, the stark contrast between a dark night sky and any bright object makes such lights far more noticeable. It is the same principle, that makes stars visible at night.\nWhy 22:00 in particular? It appears to represent an optimal balance. By this hour, the sky is fully dark, providing ideal conditions for spotting shining objects against a dark backdrop. At the same time, it is still within a reasonable timeframe when many people are likely to be outdoors. In contrast, sightings tend to decline past midnight, likely due to reduced human presence and decreased observational activity during the early morning hours.\n\n\nSightings heatmap together with airforce bases\nNow we want to explore a different angle, we therefore wish to plot the geographical data. This results in a heat map. Along with the sighting distribution the heat map also contains airforce bases, in order to explore Air Force flights influence on UFO sightings. We suspect that aircrafts in particular might often be mistaken for UFO and in particular aircrafts from military bases. Since the often travel in more secrecy and might not have the usual look of an airplane.The heat map will only contain Air Force bases, despite other branches of the U.S Military containing aircraft, due to simplicity as it would be impossible to distinguish between an Army Airbase, and an regular infantry base.\n\n\nCode\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom folium import plugins\nfrom folium.plugins import HeatMap\nimport folium\nfrom branca.element import Template, MacroElement\n\ndata = pd.read_csv(\"data/complete.csv\", on_bad_lines='skip')\ndata['datetime'] = pd.to_datetime(data['datetime'], errors='coerce')\ndf=data[data[\"country\"]==\"us\"].sort_index(level=\"datetime\")\ndf = df.dropna(subset=['datetime'])\ndf = df.sort_values(by='datetime').reset_index(drop=True)\ndf=df.dropna()\n\nmilbases=pd.read_csv(\"data/clean_military_bases.csv\")\nmilcomp=milbases[\"component\"]\nletters=[i[0:2] for i in milbases[\"component\"]]\n\nmilbases=milbases[(milcomp==\"AF Guard\" ) |(milcomp==\"AF Reserve\" )| (milcomp==\"AF Active\")]\n\nmilbasesl=milbases[[\"latitude\",\"longitude\"]]\n\n# Create your map\nmap_hooray = folium.Map(location=[40.80887462217925, -101.64736435756755], zoom_start=4)\n\n# Process your heatmap data\ndf['latitude'] = df['latitude'].astype(float)\ndf['longitude'] = df['longitude'].astype(float)\nheat_df = df[['latitude', 'longitude']].dropna()\nheat_data = [[row['latitude'], row['longitude']] for index, row in heat_df.iterrows()]\n\n# Add heatmap with adjusted parameters for less density\nHeatMap(\n    heat_data,\n    radius=5,             # smaller spread\n    blur=1,               # smoother blending\n    max_opacity=0.5,       # reduce color saturation\n    min_opacity=0.3,       # allow fade for low-density areas\n    use_local_extrema=False  # keep global scale\n).add_to(map_hooray)\n\n# Add circle markers for different components\nfor index, row in milbasesl[milcomp == \"AF Reserve\"].iterrows():\n    folium.CircleMarker(\n        location=[row['latitude'], row['longitude']],\n        radius=3,\n        color='#6610f2',\n        fill=True,\n        fill_color='#6610f2',\n        fill_opacity=0.6\n    ).add_to(map_hooray)\n\nfor index, row in milbasesl[milcomp == \"AF Active\"].iterrows():\n    folium.CircleMarker(\n        location=[row['latitude'], row['longitude']],\n        radius=3,\n        color='#007bff',\n        fill=True,\n        fill_color='#007bff',\n        fill_opacity=0.6\n    ).add_to(map_hooray)\n\nfor index, row in milbasesl[milcomp == \"AF Guard\"].iterrows():\n    folium.CircleMarker(\n        location=[row['latitude'], row['longitude']],\n        radius=3,\n        color='#09772f',\n        fill=True,\n        fill_color='#09772f',\n        fill_opacity=0.6\n    ).add_to(map_hooray)\n\n# Custom legend (unchanged)\ntemplate = \"\"\"\n{% macro html(this, kwargs) %}\n&lt;!doctype html&gt;\n&lt;html lang=\"en\"&gt;\n&lt;head&gt;\n  &lt;meta charset=\"utf-8\"&gt;\n  &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"&gt;\n  &lt;title&gt;Heatmap Legend&lt;/title&gt;\n  &lt;link rel=\"stylesheet\" href=\"//code.jquery.com/ui/1.12.1/themes/base/jquery-ui.css\"&gt;\n  &lt;script src=\"https://code.jquery.com/jquery-1.12.4.js\"&gt;&lt;/script&gt;\n  &lt;script src=\"https://code.jquery.com/ui/1.12.1/jquery-ui.js\"&gt;&lt;/script&gt;\n  &lt;script&gt;\n  $( function() {\n    $( \"#maplegend\" ).draggable({\n        start: function (event, ui) {\n            $(this).css({ right: \"auto\", top: \"auto\", bottom: \"auto\" });\n        }\n    });\n  });\n  &lt;/script&gt;\n&lt;/head&gt;\n&lt;body&gt;\n&lt;div id='maplegend' class='maplegend' \n    style='position: absolute; z-index:9999; border:2px solid grey; background-color:rgba(255, 255, 255, 0.8);\n     border-radius:6px; padding: 10px; font-size:14px; right: 20px; bottom: 20px;'&gt;\n     \n&lt;div class='legend-title'&gt;Legend&lt;/div&gt;\n&lt;div class='legend-scale'&gt;\n  &lt;ul class='legend-labels'&gt;\n    &lt;li&gt;&lt;span style='background:#6610f2;opacity:0.7;'&gt;&lt;/span&gt;AF Active&lt;/li&gt;\n    &lt;li&gt;&lt;span style='background:#007bff;opacity:0.7;'&gt;&lt;/span&gt;AF Reserve&lt;/li&gt;\n    &lt;li&gt;&lt;span style='background:#09772f;opacity:0.7;'&gt;&lt;/span&gt;AF Guard&lt;/li&gt;\n  &lt;/ul&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n\n&lt;style type='text/css'&gt;\n  .maplegend .legend-title {\n    text-align: left;\n    margin-bottom: 5px;\n    font-weight: bold;\n    font-size: 90%;\n    }\n  .maplegend .legend-scale ul {\n    margin: 0;\n    padding: 0;\n    float: left;\n    list-style: none;\n    }\n  .maplegend .legend-scale ul li {\n    font-size: 80%;\n    list-style: none;\n    margin-left: 0;\n    line-height: 18px;\n    margin-bottom: 2px;\n    }\n  .maplegend ul.legend-labels li span {\n    display: block;\n    float: left;\n    height: 16px;\n    width: 30px;\n    margin-right: 5px;\n    margin-left: 0;\n    border: 1px solid #999;\n    }\n  .maplegend .legend-source {\n    font-size: 80%;\n    color: #777;\n    clear: both;\n    }\n  .maplegend a {\n    color: #777;\n    }\n&lt;/style&gt;\n{% endmacro %}\n\"\"\"\n\n# Add the legend to the map\nmacro = MacroElement()\nmacro._template = Template(template)\nmap_hooray.get_root().add_child(macro)\n\n# Display the map\nmap_hooray\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\nFigure 4: The heatmap shows looks at the locations of the reported sightnings. We have included the location of different military air force bases. It seems that there often are a lot of sightings around big cities which also sometimes have airforce bases. But sometimes places where there is only airforce bases also sees an increase in sightings\nFigure 4 reveals a clear pattern: regions in proximity to active airbases tend to exhibit a high density of UFO sightings. One plausible explanation is that these sightings may, in fact, correspond to military aircraft activity. Given that military aircraft are routinely operated near their bases regardless of weather conditions or time of day it is not unreasonable to assume that experimental or unfamiliar aircraft flying at night could be mistaken for unidentified flying objects by unsuspecting observers. Since airbases are geographically fixed, such misidentifications would naturally accumulate in the same locations over time, resulting in noticeable clusters of sightings. This is also what we see in some of the states with low population but still fine number of UFO sightings.\nAnother notable observation from Figure 4 is the clear disparity in the density and distribution of UFO sightings between the eastern and western regions of the United States. Sightings appear to be significantly more frequent in the east, where high density areas form a nearly continuous band across much of the region. This pattern is especially pronounced around major metropolitan centers such as New York, Chicago, and Washington, D.C, where sightings are heavily clustered. In contrast, the western United States shows a markedly different pattern. Sightings in this region are largely confined to the coasts and major urban centers, including cities like Los Angeles and San Francisco. Vast interior areas of the west, including parts of the Rocky Mountains and Great Basin, exhibit little to no reported activity.\nWe suspect the reason between this great disparity, is most likely population size and density. As we mentioned two large areas of the west ie. The Rocky Mountains and Great Basin has almost no sightings reported. These two areas are also very sparsely populated, while coastal and urban centers such as Los Angeles, San Francisco, Seattle, Salt Lake City and Denver still report large amounts of sightings. This could indicate that reported UFO sightings are correlated with population size and maybe not so much correlated with military bases. It is also a bit difficult to see this since a lot of the military bases are around cities. We still see states with low population, which has spikes of sightings around military bases but not a significant amount enough to be conclusive about.\n\n\nCorrelation between population and UFO sightings\nThe heatmap suggest that there is a fairly stark correlation between population and number of sigtings. This is something we want look into in the following plots. First we take a look at the correlation between populaton and sighitngs for all states and years.\n\n\nCode\nimport pandas as pd\nfrom bokeh.plotting import figure, show, output_notebook\nfrom bokeh.models import ColumnDataSource, CustomJS, HoverTool, TapTool\nfrom bokeh.palettes import viridis\n\noutput_notebook(hide_banner=1)\n\nexcluded = {'pr', 'dc'}\n\n# Load and clean population data\ndata = pd.read_csv(\"data/historical_state_population_by_year.csv\", on_bad_lines='skip')\ndata = data[(data['year'] &gt;= 1950) & (data['year'] &lt;= 2014)]\ndata[\"state\"] = data[\"state\"].str.lower()\ndata = data[data[\"state\"].isin(excluded) == False]\ndata = data.dropna(subset=['state'])\n\n# Load and clean UFO data\ndf = pd.read_csv(\"data/complete.csv\", on_bad_lines='skip')\ndf['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')\ndf = df[df[\"country\"] == \"us\"]\ndf = df[df[\"state\"].isin(excluded) == False]\ndf = df.dropna(subset=['datetime'])\ndf['year'] = df['datetime'].dt.year\ndf = df[(df['year'] &gt;= 1950) & (df['year'] &lt;= 2014)]\n\n# Group and merge\ngrouped = df.groupby(['state', 'year']).size().reset_index(name='num_sightings')\nall_states = sorted(df['state'].unique())\nall_years = range(1950, 2015)\nfull_index = pd.MultiIndex.from_product([all_states, all_years], names=['state', 'year'])\nsightings_summary = grouped.set_index(['state', 'year']).reindex(full_index, fill_value=0).reset_index()\nmerged = pd.merge(data, sightings_summary, on=['state', 'year']).dropna(subset=['population', 'num_sightings'])\nmerged['population'] = merged['population'] / 1_000_000\n# Use a colorblind-friendly palette\ncolorblind_palette = [\n    \"#007bff\",  # blue\n    \"#6610f2\",  # indigo\n    \"#6f42c1\",  # purple\n    \"#e83e8c\",  # pink\n    \"#d9534f\",  # red\n    \"#fd7e14\",  # orange\n    \"#f0ad4e\",  # yellow\n    \"#4bbf73\",  # green\n    \"#20c997\",  # teal\n    \"#1f9bcf\"   # cyan\n]\n\nextended_palette = (colorblind_palette * ((len(all_states) // len(colorblind_palette)) + 1))[:len(all_states)]\nstate_color_map = dict(zip(all_states, extended_palette))\n\nmerged['color'] = merged['state'].map(state_color_map)\nmerged['alpha'] = [0.6] * len(merged)\n\nsource = ColumnDataSource(merged)\n\n# Plot setup\np = figure(title=\"UFO Sightings vs Population (1950‚Äì2014)\",\n           x_axis_label=\"Population\", y_axis_label=\"Number of Sightings\",\n           tools=\"pan,wheel_zoom,box_zoom,reset,tap,hover\",\n           width=640, height=600,background_fill_color=\"#f5f5f5\")\n\n# Draw points\np.circle('population', 'num_sightings',\n         source=source,\n         size=6,\n         color='color',\n         alpha='alpha',\n         line_color=None)\n\n# Hover tool: passive inspection\nhover = p.select_one(HoverTool)\nhover.tooltips = [\n    (\"State\", \"@state\"),\n    (\"Year\", \"@year\"),\n    (\"Population\", \"@population{0,0}\"),\n    (\"Sightings\", \"@num_sightings\")\n]\n\n# Tap tool: highlights all from the clicked state\ntap_callback = CustomJS(args=dict(source=source), code=\"\"\"\n    const selected = source.selected.indices[0];\n    const data = source.data;\n    const N = data['state'].length;\n\n    if (selected == null) return;\n\n    const selected_state = data['state'][selected];\n\n    for (let i = 0; i &lt; N; i++) {\n        data['alpha'][i] = (data['state'][i] === selected_state) ? 1.0 : 0.1;\n    }\n    source.change.emit();\n\"\"\")\n\ntaptool = p.select_one(TapTool)\ntaptool.callback = tap_callback\n\nshow(p)\n\n\n\n\n\n\n  \n\n\n\n\n\nFigure 5: A chart which shows the UFO sightings over population over the last from 1950 to 2014. The different states are highligthed with different colors. One sees that there is a lot of smaller populations which does not have that many sightings. One also sees that some states have seen a major increase in sigthings even though there population remained rather stable\nWe are also interested in just looking at particular years.\n\n\nCode\nfrom bokeh.io import output_notebook, show\nfrom bokeh.plotting import figure\nfrom bokeh.models import ColumnDataSource, Slider, CustomJS\nfrom bokeh.layouts import column\nfrom sklearn.linear_model import LinearRegression\nimport pandas as pd\nimport numpy as np\nimport json\n\noutput_notebook(hide_banner=True)\n\n# Load and clean population data\nexcluded = {'pr', 'dc'}\ndata = pd.read_csv(\"data/historical_state_population_by_year.csv\", on_bad_lines='skip')\ndata = data[(data['year'] &gt;= 1950) & (data['year'] &lt;= 2014)]\ndata[\"state\"] = data[\"state\"].str.lower()\ndata = data[~data[\"state\"].isin(excluded)]\ndata = data.dropna(subset=['state'])\n\n# Load and clean sightings data\ndf = pd.read_csv(\"data/complete.csv\", on_bad_lines='skip')\ndf['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')\ndf = df[df[\"country\"] == \"us\"]\ndf = df[~df[\"state\"].isin(excluded)]\ndf = df.dropna(subset=['datetime'])\ndf = df.sort_values(by='datetime').reset_index(drop=True)\ndf['year'] = df['datetime'].dt.year\ndf = df[(df['year'] &gt;= 1950) & (df['year'] &lt;= 2014)]\n\n# Group by state and year\ngrouped = df.groupby(['state', 'year']).size().reset_index(name='num_sightings')\n\n# Create complete grid\nall_states = df['state'].unique()\nall_years = range(1950, 2015)\nfull_index = pd.MultiIndex.from_product([all_states, all_years], names=['state', 'year'])\nsightings_summary = grouped.set_index(['state', 'year']).reindex(full_index, fill_value=0).reset_index()\n\n# Merge datasets\nmerged = pd.merge(data, sightings_summary, on=['year', 'state'])\n\n# Compute correlation per year\nstate_correlations = merged.groupby('year').apply(\n    lambda g: g['population'].corr(g['num_sightings'])\n).reset_index(name='correlation')\n\n# Prepare Bokeh data structures\nyear_data = {}\nplot_meta = {}\n\nfor year in sorted(merged['year'].unique()):\n    df_year = merged[merged['year'] == year]\n    x = df_year['population'].values/1000000\n    y = df_year['num_sightings'].values\n\n    if len(x) &gt; 1:\n        model = LinearRegression()\n        model.fit(x.reshape(-1, 1), y)\n        y_pred = model.predict(x.reshape(-1, 1))\n        slope = model.coef_[0]\n        intercept = model.intercept_\n        ss_res = np.sum((y - y_pred) ** 2)\n        ss_tot = np.sum((y - np.mean(y)) ** 2)\n        r2 = 1 - ss_res / ss_tot\n    else:\n        y_pred = np.zeros_like(x)\n        slope = intercept = r2 = 0\n\n    corr = state_correlations[state_correlations['year'] == year]['correlation'].values[0]\n\n    year_data[str(year)] = {\n        'x': x.tolist(),\n        'y': y.tolist(),\n        'y_pred': y_pred.tolist()\n    }\n\n    plot_meta[str(year)] = {\n        'title': f\"UFO Sightings vs Population - {year} | Correlation = {corr:.2f}\"\n    }\n\n# Bokeh plotting\ninitial_year = \"1987\"\nsource = ColumnDataSource(data=year_data[initial_year])\n\np = figure(height=400, width=640,\n           title=plot_meta[initial_year]['title'],\n           x_axis_label='Population (per milion)', y_axis_label='Number of Sightings',background_fill_color=\"#f5f5f5\")\n\np.circle('x', 'y', size=8, source=source,color=\"#007bff\")\np.line('x', 'y_pred', source=source, line_width=2, \ncolor='#d9534f')\n\n#p.legend.location = \"top_left\"\n\n# Slider and JS Callback\nslider = Slider(start=merged['year'].min(), end=merged['year'].max(), value=int(initial_year), step=1, title=\"Year\")\n\ncallback = CustomJS(args=dict(source=source, slider=slider, plot=p),\n    code=f\"\"\"\n        const year_data = {json.dumps(year_data)};\n        const meta = {json.dumps(plot_meta)};\n        const year = slider.value.toString();\n\n        source.data = year_data[year];\n        plot.title.text = meta[year].title;\n        source.change.emit();\n    \"\"\"\n)\n\nslider.js_on_change('value', callback)\n\nshow(column(slider, p))\n\n\n\n\n\n\n  \n\n\n\n\n\nFigure 6: A correlation plot over the years looking at the different states population and sightings for a chosen year. We see a rather strong correlation between the two for most years. This in turn explains our heatmap\nAn examination of Figures 5 and 6 supports the hypothesis that reported UFO sightings are positively correlated with population size. This relationship is most evident in the year 2008, which shows the highest correlation coefficient of 0.96 between state population and the number of reported sightings. In contrast, the year 1951 exhibits the lowest correlation, with a coefficient of just 0.34. But this might as well be because of a lack of datapoints. Overall, the early years of the dataset, particularly the first two decades, display a relatively weak correlation between population and sightings. However, beginning in the 1970s, the correlation becomes significantly stronger and more consistent.\nThis trend may be attributed to the growing influence of popular culture during that time. The 1970s marked a rise in public interest in UFOs and extraterrestrial life, largely driven by the emergence of films, television shows, and books that featured such themes. As these topics entered mainstream entertainment, public awareness and curiosity about UFOs likely increased. Moreover, the depiction of UFO sightings in media may have contributed to a gradual reduction in the stigma or taboo associated with reporting such events.\nIt is plausible that in the earlier decades, individuals were more hesitant to report sightings due to fear of ridicule or disbelief. As cultural perceptions shifted and UFO phenomena became more widely discussed and accepted, people may have felt more comfortable coming forward with their observations. Thus, the strengthening correlation over time could reflect not only population growth but also a growing willingness to report sightings, influenced by evolving social and cultural attitudes.\nThe previously mentioned factors help explain the overall increase in reported UFO sightings but do not fully account for the growing correlation between population size and sightings over time. To better understand this trend, it is useful to consider how observation conditions vary with geography. Interestingly, some of the best locations in the United States for observing the night sky are in sparsely populated areas, particularly in the western region. According to World Atlas@worldatlas_stargazing, four out of the six top-rated stargazing locations in the U.S. are in the West, with many of them situated in desert environments. These areas offer minimal light pollution and clear, unobstructed skies ideal conditions for observing aerial activity.\nThis suggests that in the earlier decades of the dataset, sightings may have been more likely to occur in these open and remote areas, where sky visibility is optimal but population density is low. As a result, even though sightings occurred, they were less frequent overall and less likely to be reported or to reflect population trends. Over time, as public interest in UFOs increased and reporting became more socially acceptable, sightings in more populated areas began to rise, thereby increasing the observed correlation with population. Thus, the shift in both where and how often people reported sightings may explain the growing alignment between population size and UFO sighting frequency.\n\n\nConclusion\nWe have now looked into the UFO sighting data in order to conclude if it were possible to come up with some explanations for the increase on UFO sightings over the years. We saw that releases such as ‚Äúindependence day‚Äù and ‚Äúx-files‚Äù might have an impact since the sighting increased around there time of relesase together with the fact that it makes it more socially acceptable to report UFO sigthings. Another observation was that population and number of sigthigns were greatly correlated and togehter with the fact that most of the sightings were after dark and ‚Äúlight‚Äù. One then might suspect that a lot of the UFO‚Äôs where in fact aircrafts. This is even more likely since the number of aircraft over the years has also significantly increased as reported by ICAO. This in turn also explain why there were an increase of sightings around airforce bases. Because of the fact that there often were more densely populated rather than conclusively leading to an increase in sightings which we initally suspected.\n\n\n\n\n\nReferences\n\nCBC News. 2009. ‚ÄúRecord British UFO Sightings in 1990s.‚Äù https://www.cbc.ca/news/world/record-british-ufo-sightings-in-1990s-1.817993.\n\n\nInternational Civil Aviation Organization. n.d. ‚ÄúFacts and Figures ‚Äì World Economy Data.‚Äù https://www.icao.int/sustainability/pages/facts-figures_worldeconomydata.aspx."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This site is created to share insights and updates about our social data project. Stay tuned for more information and findings!"
  },
  {
    "objectID": "Plots/dummyfil.html",
    "href": "Plots/dummyfil.html",
    "title": "Social data analysis and visualization project",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndata = pd.read_csv(\"../data/complete.csv\", on_bad_lines='skip')\ndata['datetime'] = pd.to_datetime(data['datetime'], errors='coerce')\ndf=data[data[\"country\"]==\"us\"].sort_index(level=\"datetime\")\ndf = df.dropna(subset=['datetime'])\ndf = df.sort_values(by='datetime').reset_index(drop=True)\ndf=df.dropna()\nhourtime=df[\"time\"]=df[\"datetime\"].dt.hour\nplt.hist(hourtime, bins=24, range=(0, 24), density=True, alpha=0.5, color='blue')\nplt.xlabel('Hour of the Day')\n\nC:\\Users\\anton\\AppData\\Local\\Temp\\ipykernel_56424\\2783440738.py:4: DtypeWarning: Columns (5,9) have mixed types. Specify dtype option on import or set low_memory=False.\n  data = pd.read_csv(\"../data/complete.csv\", on_bad_lines='skip')\n\n\nText(0.5, 0, 'Hour of the Day')"
  },
  {
    "objectID": "Plots/time series barplot.html",
    "href": "Plots/time series barplot.html",
    "title": "Social data analysis and visualization project",
    "section": "",
    "text": "import pandas as pd\ndata = pd.read_csv(\"../data/complete.csv\", on_bad_lines='skip')\ndata['datetime'] = pd.to_datetime(data['datetime'], errors='coerce')\ndf=data[data[\"country\"]==\"us\"].sort_index(level=\"datetime\")\ndf = df.dropna(subset=['datetime'])\ndf = df.sort_values(by='datetime').reset_index(drop=True)\ndf=df.dropna()\n\nC:\\Users\\anton\\AppData\\Local\\Temp\\ipykernel_132960\\3343208995.py:2: DtypeWarning: Columns (5,9) have mixed types. Specify dtype option on import or set low_memory=False.\n  data = pd.read_csv(\"../data/complete.csv\", on_bad_lines='skip')\n\n\n\n#import pandas_profiling\n\n\nimport pandas as pd\nfrom bokeh.plotting import figure, show\nfrom bokeh.models import ColumnDataSource, HoverTool, Span\nfrom bokeh.io import output_notebook\n\n# output_notebook()  # Uncomment if using Jupyter Notebook\n\n# === Load & Clean Data ===\ndata = pd.read_csv(\"../data/complete.csv\", on_bad_lines='skip')\ndata['datetime'] = pd.to_datetime(data['datetime'], errors='coerce')\ndf = data[data[\"country\"] == \"us\"].dropna(subset=['datetime'])\ndf['year'] = df['datetime'].dt.year\nyear_counts = df['year'].value_counts().sort_index()\n\nsightings_source = ColumnDataSource(data=dict(\n    year=year_counts.index.tolist(),\n    count=year_counts.values.tolist()\n))\n\n# === Annotated Media Events ===\nalien_media = {\n    1951: (\"The Day the Earth Stood Still\", \"movie\"),\n    1977: (\"Close Encounters\", \"movie\"),\n    1979: (\"Alien\", \"movie\"),\n    1982: (\"E.T.\", \"movie\"),\n    1986: (\"Aliens\", \"movie\"),\n    1993: (\"The X-Files (TV)\", \"tv\"),\n    1996: (\"Independence Day\", \"movie\"),\n    1998: (\"X-Files: The Movie\", \"tv\"),\n    2002: (\"Signs\", \"movie\"),\n    2009: (\"District 9\", \"movie\"),\n    2014: (\"Edge of Tomorrow\", \"movie\")\n}\n\nmedia_data = {\n    'year': [],\n    'count': [],\n    'title': [],\n    'type': []\n}\nfor year, (title, typ) in alien_media.items():\n    if year in year_counts.index:\n        media_data['year'].append(year)\n        media_data['count'].append(year_counts[year])\n        media_data['title'].append(title)\n        media_data['type'].append(typ)\n\nmedia_source = ColumnDataSource(media_data)\n\n# === Create Bokeh Plot ===\np = figure(\n    width=1000, height=500,\n    background_fill_color=\"#0f0f1f\", border_fill_color=\"#0f0f1f\",\n    title=\"U.S. UFO Sightings with Major Alien Media Releases\",\n    x_axis_label=None, y_axis_label=None,\n    x_range=(min(year_counts.index)-1, max(year_counts.index)+1),\n    tools=\"\", toolbar_location=None\n)\n\np.vbar(x='year', top='count', width=0.8, source=sightings_source,\n       color=\"#00ff99\", line_color=None, legend_label=\"Sightings\")\n\n# Neon markers for media events\nmedia_renderer = p.circle(x='year', y='count', size=10,\n                          color=\"#ff3366\", alpha=0.9, source=media_source,\n                          legend_label=\"Media Event\")\n\n# Tooltip for media events\np.add_tools(HoverTool(\n    renderers=[media_renderer],\n    tooltips=[(\"Media\", \"@title\"), (\"Year\", \"@year\"), (\"Sightings\", \"@count\")],\n    mode='mouse'\n))\n\n# Styling polish\np.xaxis.major_label_text_color = \"#cccccc\"\np.yaxis.major_label_text_color = \"#cccccc\"\np.xaxis.axis_line_color = \"#333333\"\np.yaxis.axis_line_color = \"#333333\"\np.xgrid.grid_line_color = None\np.ygrid.grid_line_color = \"#222244\"\np.title.text_color = \"#eeeeee\"\np.title.text_font_size = \"16pt\"\np.title.align = \"center\"\np.legend.label_text_color = \"#cccccc\"\np.legend.background_fill_alpha = 0.0\np.legend.location = \"top_left\"\n\n# Show it\nshow(p)\n\nC:\\Users\\anton\\AppData\\Local\\Temp\\ipykernel_132960\\730181234.py:9: DtypeWarning: Columns (5,9) have mixed types. Specify dtype option on import or set low_memory=False.\n  data = pd.read_csv(\"../data/complete.csv\", on_bad_lines='skip')\nBokehDeprecationWarning: 'circle() method with size value' was deprecated in Bokeh 3.4.0 and will be removed, use 'scatter(size=...) instead' instead.\n\n\n\nimport pandas as pd\nfrom bokeh.plotting import figure, show\nfrom bokeh.models import ColumnDataSource, HoverTool, LabelSet\nfrom bokeh.palettes import Category20\n\n# === Load and preprocess data ===\ndata = pd.read_csv(\"../data/complete.csv\", on_bad_lines='skip')\ndata[\"datetime\"] = pd.to_datetime(data[\"datetime\"], errors=\"coerce\")\ndf = data[data[\"country\"] == \"us\"].dropna(subset=[\"datetime\", \"shape\"])\ndf[\"year\"] = df[\"datetime\"].dt.year\n\n# === Compute total sightings per year (all shapes) ===\ntotals = df.groupby(\"year\").size()\ntotals = totals[totals.index &gt;= 1960]\n\n# === Full shape distribution (pivot) ===\nshape_counts_all = df.groupby([\"year\", \"shape\"]).size().unstack(fill_value=0)\n\n# === Select top 5 shapes, group rest as 'uncommon shapes' ===\nshape_totals = shape_counts_all.sum().sort_values(ascending=False)\ntop_shapes = shape_totals.head(5).index\nother_shapes = shape_totals.index.difference(top_shapes)\n\n# Create new DataFrame for top 5 + 'uncommon shapes'\nshape_counts = shape_counts_all[top_shapes].copy()\nshape_counts[\"uncommon shapes\"] = shape_counts_all[other_shapes].sum(axis=1)\nshape_counts = shape_counts[shape_counts.index &gt;= 1960]\n\n# === Stack plot source ===\nfinal_shapes = [\"uncommon shapes\"] + list(top_shapes)  # Move to bottom\nsource_data = {\"year\": shape_counts.index.tolist()}\ncolors = Category20[20][:len(final_shapes)]\nfor s in final_shapes:\n    source_data[s] = shape_counts[s].values\nsource = ColumnDataSource(source_data)\n\n# === Emoji map ===\nemoji_map = {\n    \"light\": \"üí°\", \"triangle\": \"üî∫\", \"circle\": \"‚≠ï\",\n    \"fireball\": \"üî•\", \"unknown\": \"‚ùì\", \"uncommon shapes\": \"üõ∏\"\n}\n\n# === Media events ===\nmedia = {\n    1951: \"The Day the Earth Stood Still\",\n    1977: \"Close Encounters\", 1979: \"Alien\", 1982: \"E.T.\",\n    1986: \"Aliens\", 1993: \"The X-Files (TV)\", 1996: \"Independence Day\",\n    1998: \"X-Files: The Movie\", 2002: \"Signs\",\n    2009: \"District 9\", 2014: \"Edge of Tomorrow\"\n}\nmedia_years = [y for y in media if y in totals.index]\nmedia_source = ColumnDataSource(data=dict(\n    year=media_years,\n    count=[totals[y] for y in media_years],\n    title=[media[y] for y in media_years]\n))\n\n# === Bokeh figure ===\nxmin, xmax = shape_counts.index.min(), shape_counts.index.max()\np = figure(\n    width=1000, height=500,\n    x_range=(1960, xmax + 3),\n    y_range=(0, shape_counts.sum(axis=1).max() * 1.15),\n    background_fill_color=\"#0f0f1f\",\n    title=\"U.S. UFO Shape Distribution Over Time (All Shapes)\",\n    tools=\"\", toolbar_location=None\n)\n\n# === Area stack ===\np.varea_stack(\n    stackers=final_shapes,\n    x=\"year\",\n    color=colors,\n    legend_label=[f\"{emoji_map.get(s, 'üõ∏')} {s}\" for s in final_shapes],\n    source=source\n)\n\n# Then reverse the legend manually (Bokeh workaround)\np.legend.items = list(reversed(p.legend.items))\n\n\n\n\n# === Media dots ===\nmedia_renderer = p.circle(\n    'year', 'count',\n    source=media_source,\n    size=12,\n    fill_color=\"#ffd700\",\n    line_color=\"white\",\n    line_width=1.3,\n    legend_label=\"Media Event\",\n    level=\"overlay\"\n)\np.add_tools(HoverTool(\n    renderers=[media_renderer],\n    tooltips=[(\"Movie\", \"@title\"), (\"Year\", \"@year\"), (\"Sightings\", \"@count\")],\n    mode=\"mouse\", point_policy=\"follow_mouse\"\n))\n\n# === Emojis ===\nrecent = shape_counts.tail(25)\nmax_h = recent.sum(axis=1).max()\nx_pts, y_pts, emojis, sizes = [], [], [], []\nfor i, s in enumerate(final_shapes):\n    yr = recent[s].idxmax()\n    below = recent[final_shapes[:i]].loc[yr].sum()\n    band = recent[s].loc[yr]\n    x_pts.append(yr)\n    y_pts.append(below + band / 2)\n    emojis.append(emoji_map.get(s, \"üõ∏\"))\n    sizes.append(f\"{10 + band / max_h * 16 - 4:.0f}pt\")\n\nemoji_source = ColumnDataSource(dict(x=x_pts, y=y_pts, emoji=emojis, size=sizes))\np.add_layout(LabelSet(\n    x='x', y='y', text='emoji', source=emoji_source,\n    text_font_size='size', text_align=\"center\", text_baseline=\"middle\"\n))\n\n# === Style ===\np.xaxis.axis_label = \"Year\"\np.yaxis.axis_label = \"Sightings\"\np.xaxis.major_label_text_color = \"#cccccc\"\np.yaxis.major_label_text_color = \"#cccccc\"\np.xaxis.axis_line_color = \"#333333\"\np.yaxis.axis_line_color = \"#333333\"\np.xgrid.grid_line_color = None\np.ygrid.grid_line_color = \"#222244\"\np.title.text_color = \"#eeeeee\"\np.title.text_font_size = \"16pt\"\np.legend.label_text_color = \"#ffffff\"\np.legend.background_fill_alpha = 0\np.legend.location = \"top_left\"\np.legend.label_text_font_size = \"9pt\"\n\nshow(p)\n\nC:\\Users\\anton\\AppData\\Local\\Temp\\ipykernel_132960\\3202122139.py:7: DtypeWarning: Columns (5,9) have mixed types. Specify dtype option on import or set low_memory=False.\n  data = pd.read_csv(\"../data/complete.csv\", on_bad_lines='skip')\nBokehDeprecationWarning: 'circle() method with size value' was deprecated in Bokeh 3.4.0 and will be removed, use 'scatter(size=...) instead' instead."
  },
  {
    "objectID": "Plots/military-bases.html",
    "href": "Plots/military-bases.html",
    "title": "Heatmap of military bases",
    "section": "",
    "text": "import pandas as pd\n# Read UFO sightings data\ndata = pd.read_csv(\"../data/complete.csv\", on_bad_lines='skip')\ndata['datetime'] = pd.to_datetime(data['datetime'], errors='coerce')\ndf=data[data[\"country\"]==\"us\"].sort_index(level=\"datetime\")\ndf = df.dropna(subset=['datetime'])\ndf = df.sort_values(by='datetime').reset_index(drop=True)\ndf=df.dropna()\n\n# Read military bases data\nmilitary_bases = pd.read_csv(\"../data/military-bases.csv\", on_bad_lines='skip')\nmilitary_bases = military_bases.dropna()\n\n# Display military bases data\nprint(\"\\nMilitary Bases Data:\")\nmilitary_bases\n\nC:\\Users\\anton\\AppData\\Local\\Temp\\ipykernel_111696\\1580756030.py:3: DtypeWarning: Columns (5,9) have mixed types. Specify dtype option on import or set low_memory=False.\n  data = pd.read_csv(\"../data/complete.csv\", on_bad_lines='skip')\n\n\n\nMilitary Bases Data:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGeo Point;Geo Shape;OBJECTID_1;OBJECTID;COMPONENT;Site Name;Joint Base;State Terr;COUNTRY;Oper Stat;PERIMETER;AREA;Shape_Leng;Shape_Area\n\n\n\n\n31.230999\n-85.6506347178;\"{\"\"coordinates\"\": [[[-85.65462565497243\n31.234178331412515]\n[-85.65280405303592\n31.2350202819558]\n[-85.65101108759404\n31.233844887000856]\n[-85.64624105229998\n31.231687174187147]\n[-85.6461603431633\n31.227908115185613]\n[-85.64979400602967\n31.22793346599952]\n[-85.65055293422273\n31.22819845388161]\n[-85.65114885861591\n31.228358922650713]\n[-85.65448605767558\n31.229254906742018]\n[-85.65462565497243\n31.234178331412515]]]\n\"\"type\"\": \"\"Polygon\"\"}\";26;65;Army Active;All...\n\n\n29.884619\n-98.2193812601;\"{\"\"coordinates\"\": [[[-98.21405296403519\n29.881741788407666]\n[-98.22093997631431\n29.87525638900559]\n[-98.22688073381588\n29.880714298886854]\n[-98.22376613997854\n29.8839619002862]\n[-98.22267722644564\n29.891689856087375]\n[-98.2140001260285\n29.89308936826227]\n[-98.21404370420125\n29.889994012243857]\n[-98.21404924231497\n29.889815498432725]\n[-98.21409100050096\n29.884640003341854]\n[-98.21405296403519\n29.881741788407666]]]\n\"\"type\"\": \"\"Polygon\"\"}\";423;2954;AF Active;Ca...\n\n\n13.310684\n144.736799463;\"{\"\"coordinates\"\": [[[144.74050133252663\n13.310010427767008]\n[144.7405013603744\n13.30973491498884]\n[144.7405016460386\n13.307058682780797]\n[144.73679989806027\n13.307058286770022]\n[144.733098159065\n13.307057834810683]\n[144.73309767307646\n13.31068323745712]\n[144.7330971772064\n13.314308639156133]\n[144.73679902579607\n13.314309070121853]\n[144.74050088336895\n13.314309446014882]\n[144.74050133252663\n13.310010427767008]]]\n\"\"type\"\": \"\"Polygon\"\"}\";664;5610;Navy Active;...\n\n\n38.760289\n-104.301342147;\"{\"\"coordinates\"\": [[[-104.3037858883342\n38.781215702234775]\n[-104.30348866455277\n38.76687622422326]\n[-104.29908696906791\n38.76691106643378]\n[-104.29858255156117\n38.75036433784128]\n[-104.30319186477617\n38.75033028410978]\n[-104.30369826396647\n38.76687460696151]\n[-104.30399642558903\n38.78121306359585]\n[-104.30428333940594\n38.795705506983]\n[-104.30407363488939\n38.79570815838814]\n[-104.3037858883342\n38.781215702234775]]]\n\"\"type\"\": \"\"Polygon\"\"}\";295;2498;AF Active;US...\n\n\n39.823370\n-89.6708742707;\"{\"\"coordinates\"\": [[[-89.66858233781238\n39.83064753161304]\n[-89.66842497722912\n39.81974738310147]\n[-89.66839715370982\n39.81781897541764]\n[-89.6683724500395\n39.81610674313765]\n[-89.67313007690454\n39.81606001154887]\n[-89.67313228586183\n39.81620299588274]\n[-89.6733774864085\n39.827663902287256]\n[-89.67339565124186\n39.83025113394826]\n[-89.67221159174736\n39.83068336257657]\n[-89.66858233781238\n39.83064753161304]]]\n\"\"type\"\": \"\"Polygon\"\"}\";494;3731;Army Guard;N...\n\n\n\n\n\n\n\n\n# Print the column names to see what we're working with\nprint(\"Columns in military_bases DataFrame:\")\nprint(military_bases.columns)\n\n# Also let's look at the first few rows to understand the data structure\nprint(\"\\nFirst few rows of military_bases:\")\nprint(military_bases.head())\n\nColumns in military_bases DataFrame:\nIndex(['Geo Point;Geo Shape;OBJECTID_1;OBJECTID;COMPONENT;Site Name;Joint Base;State Terr;COUNTRY;Oper Stat;PERIMETER;AREA;Shape_Leng;Shape_Area'], dtype='object')\n\nFirst few rows of military_bases:\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Geo Point;Geo Shape;OBJECTID_1;OBJECTID;COMPONENT;Site Name;Joint Base;State Terr;COUNTRY;Oper Stat;PERIMETER;AREA;Shape_Leng;Shape_Area\n31.230999 -85.6506347178;\"{\"\"coordinates\"\": [[[-85.654625... 31.234178331412515] [-85.65280405303592  31.2350202819558]  [-85.65101108759404  31.233844887000856] [-85.64624105229998  31.231687174187147] [-85.6461603431633   31.227908115185613] [-85.64979400602967  31.22793346599952] [-85.65055293422273  31.22819845388161]  [-85.65114885861591  31.228358922650713] [-85.65448605767558  31.229254906742018] [-85.65462565497243 31.234178331412515]]]   \"\"type\"\": \"\"Polygon\"\"}\";26;65;Army Active;All...                                                                                      \n29.884619 -98.2193812601;\"{\"\"coordinates\"\": [[[-98.214052... 29.881741788407666] [-98.22093997631431  29.87525638900559] [-98.22688073381588  29.880714298886854] [-98.22376613997854  29.8839619002862]   [-98.22267722644564  29.891689856087375] [-98.2140001260285   29.89308936826227] [-98.21404370420125  29.889994012243857] [-98.21404924231497  29.889815498432725] [-98.21409100050096  29.884640003341854] [-98.21405296403519 29.881741788407666]]]   \"\"type\"\": \"\"Polygon\"\"}\";423;2954;AF Active;Ca...                                                                                      \n13.310684 144.736799463;\"{\"\"coordinates\"\": [[[144.7405013... 13.310010427767008] [144.7405013603744   13.30973491498884] [144.7405016460386   13.307058682780797] [144.73679989806027  13.307058286770022] [144.733098159065    13.307057834810683] [144.73309767307646  13.31068323745712] [144.7330971772064   13.314308639156133] [144.73679902579607  13.314309070121853] [144.74050088336895  13.314309446014882] [144.74050133252663 13.310010427767008]]]   \"\"type\"\": \"\"Polygon\"\"}\";664;5610;Navy Active;...                                                                                      \n38.760289 -104.301342147;\"{\"\"coordinates\"\": [[[-104.30378... 38.781215702234775] [-104.30348866455277 38.76687622422326] [-104.29908696906791 38.76691106643378]  [-104.29858255156117 38.75036433784128]  [-104.30319186477617 38.75033028410978]  [-104.30369826396647 38.76687460696151] [-104.30399642558903 38.78121306359585]  [-104.30428333940594 38.795705506983]    [-104.30407363488939 38.79570815838814]  [-104.3037858883342 38.781215702234775]]]   \"\"type\"\": \"\"Polygon\"\"}\";295;2498;AF Active;US...                                                                                      \n39.823370 -89.6708742707;\"{\"\"coordinates\"\": [[[-89.668582... 39.83064753161304]  [-89.66842497722912  39.81974738310147] [-89.66839715370982  39.81781897541764]  [-89.6683724500395   39.81610674313765]  [-89.67313007690454  39.81606001154887]  [-89.67313228586183  39.81620299588274] [-89.6733774864085   39.827663902287256] [-89.67339565124186  39.83025113394826]  [-89.67221159174736  39.83068336257657]  [-89.66858233781238 39.83064753161304]]]    \"\"type\"\": \"\"Polygon\"\"}\";494;3731;Army Guard;N...                                                                                      \n\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Let's first look at what we're working with\nprint(\"First row of coordinates:\")\nprint(military_bases['Geo Point;Geo Shape;OBJECTID_1;OBJECTID;COMPONENT;Site Name;Joint Base;State Terr;COUNTRY;Oper Stat;PERIMETER;AREA;Shape_Leng;Shape_Area'].iloc[0])\n\n# Let's try to extract just the first part before the semicolon\ncoordinates = military_bases['Geo Point;Geo Shape;OBJECTID_1;OBJECTID;COMPONENT;Site Name;Joint Base;State Terr;COUNTRY;Oper Stat;PERIMETER;AREA;Shape_Leng;Shape_Area'].str.split(';').str[0]\n\n# Print the first few coordinates to see the format\nprint(\"\\nFirst few coordinates:\")\nprint(coordinates.head())\n\nFirst row of coordinates:\n \"\"type\"\": \"\"Polygon\"\"}\";26;65;Army Active;Allen Stagefield AL;N/A;Alabama;United States;Active;1.64138338;0.17657484;3170.6333159366786;627423.9946918904\n\nFirst few coordinates:\n31.230999  -85.6506347178;\"{\"\"coordinates\"\": [[[-85.65462565497243  31.234178331412515]  [-85.65280405303592   31.2350202819558]   [-85.65101108759404   31.233844887000856]  [-85.64624105229998   31.231687174187147]  [-85.6461603431633    31.227908115185613]  [-85.64979400602967   31.22793346599952]  [-85.65055293422273   31.22819845388161]   [-85.65114885861591   31.228358922650713]  [-85.65448605767558   31.229254906742018]  [-85.65462565497243  31.234178331412515]]]     \"\"type\"\": \"\"Polygon\"\"}\"\n29.884619  -98.2193812601;\"{\"\"coordinates\"\": [[[-98.21405296403519  29.881741788407666]  [-98.22093997631431   29.87525638900559]  [-98.22688073381588   29.880714298886854]  [-98.22376613997854   29.8839619002862]    [-98.22267722644564   29.891689856087375]  [-98.2140001260285    29.89308936826227]  [-98.21404370420125   29.889994012243857]  [-98.21404924231497   29.889815498432725]  [-98.21409100050096   29.884640003341854]  [-98.21405296403519  29.881741788407666]]]     \"\"type\"\": \"\"Polygon\"\"}\"\n13.310684  144.736799463;\"{\"\"coordinates\"\": [[[144.74050133252663   13.310010427767008]  [144.7405013603744    13.30973491498884]  [144.7405016460386    13.307058682780797]  [144.73679989806027   13.307058286770022]  [144.733098159065     13.307057834810683]  [144.73309767307646   13.31068323745712]  [144.7330971772064    13.314308639156133]  [144.73679902579607   13.314309070121853]  [144.74050088336895   13.314309446014882]  [144.74050133252663  13.310010427767008]]]     \"\"type\"\": \"\"Polygon\"\"}\"\n38.760289  -104.301342147;\"{\"\"coordinates\"\": [[[-104.3037858883342  38.781215702234775]  [-104.30348866455277  38.76687622422326]  [-104.29908696906791  38.76691106643378]   [-104.29858255156117  38.75036433784128]   [-104.30319186477617  38.75033028410978]   [-104.30369826396647  38.76687460696151]  [-104.30399642558903  38.78121306359585]   [-104.30428333940594  38.795705506983]     [-104.30407363488939  38.79570815838814]   [-104.3037858883342  38.781215702234775]]]     \"\"type\"\": \"\"Polygon\"\"}\"\n39.823370  -89.6708742707;\"{\"\"coordinates\"\": [[[-89.66858233781238  39.83064753161304]   [-89.66842497722912   39.81974738310147]  [-89.66839715370982   39.81781897541764]   [-89.6683724500395    39.81610674313765]   [-89.67313007690454   39.81606001154887]   [-89.67313228586183   39.81620299588274]  [-89.6733774864085    39.827663902287256]  [-89.67339565124186   39.83025113394826]   [-89.67221159174736   39.83068336257657]   [-89.66858233781238  39.83064753161304]]]      \"\"type\"\": \"\"Polygon\"\"}\"\nName: Geo Point;Geo Shape;OBJECTID_1;OBJECTID;COMPONENT;Site Name;Joint Base;State Terr;COUNTRY;Oper Stat;PERIMETER;AREA;Shape_Leng;Shape_Area, dtype: object\n\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Read the military bases data\nmilitary_bases = pd.read_csv(\"../data/military-bases.csv\", sep=';', on_bad_lines='skip')\n\n# Split the Geo Point column into latitude and longitude\nmilitary_bases[['latitude', 'longitude']] = military_bases['Geo Point'].str.split(',', expand=True).astype(float)\n\n# Create the scatter plot\nplt.figure(figsize=(15, 10))\nplt.scatter(military_bases['longitude'], military_bases['latitude'], \n           alpha=0.5, c='red', s=50)\nplt.title('Military Bases Locations')\nplt.xlabel('Longitude')\nplt.ylabel('Latitude')\nplt.grid(True)\n\n# Set axis limits for US\nplt.xlim(-130, -65)\nplt.ylim(25, 50)\n\n# Add state labels for some major bases\nfor idx, row in military_bases.head(10).iterrows():\n    plt.annotate(row['State Terr'], \n                (row['longitude'], row['latitude']),\n                xytext=(5, 5), textcoords='offset points')\n\nplt.show()\n\n# Print some statistics\nprint(\"Number of military bases:\", len(military_bases))\nprint(\"\\nCoordinate ranges:\")\nprint(\"Latitude range:\", military_bases['latitude'].min(), \"to\", military_bases['latitude'].max())\nprint(\"Longitude range:\", military_bases['longitude'].min(), \"to\", military_bases['longitude'].max())\n\n\n\n\n\n\n\n\nNumber of military bases: 776\n\nCoordinate ranges:\nLatitude range: 13.3106836826 to 71.3217290437\nLongitude range: -161.767465275 to 174.107140074\n\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Read the military bases data\nmilitary_bases = pd.read_csv(\"../data/military-bases.csv\", sep=';', on_bad_lines='skip')\n\n# Split the Geo Point column into latitude and longitude\nmilitary_bases[['latitude', 'longitude']] = military_bases['Geo Point'].str.split(',', expand=True).astype(float)\n\n# Create a cleaner DataFrame with just the essential columns\nclean_military_bases = military_bases[['Site Name', 'COMPONENT', 'State Terr', 'COUNTRY', 'Oper Stat', 'latitude', 'longitude']]\n\n# Rename columns to be more readable\nclean_military_bases = clean_military_bases.rename(columns={\n    'Site Name': 'site_name',\n    'COMPONENT': 'component',\n    'State Terr': 'state',\n    'COUNTRY': 'country',\n    'Oper Stat': 'operational_status'\n})\n\n# Save to a new CSV file\nclean_military_bases.to_csv('../data/clean_military_bases.csv', index=False)\n\n# Print the first few rows of the clean data\nprint(\"Clean military bases data:\")\nprint(clean_military_bases.head())\n\n# Print the shape of the clean data\nprint(\"\\nShape of clean data:\", clean_military_bases.shape)\n\nClean military bases data:\n                      site_name    component       state        country  \\\n0           Allen Stagefield AL  Army Active     Alabama  United States   \n1      Louisville Stagefield AL  Army Active     Alabama  United States   \n2  White Sands Missile Range NM  Army Active  New Mexico  United States   \n3                   Fort Monroe  Army Active    Virginia  United States   \n4                MCB Camp Smith    MC Active      Hawaii  United States   \n\n  operational_status   latitude   longitude  \n0             Active  31.230999  -85.650635  \n1             Active  31.815733  -85.649798  \n2             Active  33.159464 -106.425696  \n3           Inactive  37.013020  -76.304376  \n4             Active  21.386628 -157.905641  \n\nShape of clean data: (776, 7)"
  },
  {
    "objectID": "index.html#and-can-we-see-it-in-the-data",
    "href": "index.html#and-can-we-see-it-in-the-data",
    "title": "What is the cause of the increase in UFO sightings?",
    "section": "",
    "text": "Since the beginning of the 20th century we have reported UFO sightings. What this project is trying to do is to look at the trend of the UFO sightings and try to explain them in a way which is not attributed to an increase in actual UFOs. Since a major part of the sightings are in the US (which already indicates that something is weird is up) we are only focusing on that part of the data.\n\n\nThe first thing we want to examine is the trend of UFO sightings over the years. We choose to look at only the sightings from 1990 and further since the number of sightings is fairly low up until that point and therefore there is no meaningful insight to gain. We also look at the particular shapes of sighings and lastly we plotted some important UFO related media too see if they might contribute to the increase.\n\n\nCode\nimport pandas as pd\nfrom bokeh.plotting import figure, show\nfrom bokeh.io import output_notebook\nfrom bokeh.models import ColumnDataSource, HoverTool, LabelSet\nfrom bokeh.palettes import Category20\n\n# Render inline\noutput_notebook(hide_banner=True)\n\n# === Load & preprocess ===\ndata = pd.read_csv(\"data/complete.csv\", on_bad_lines='skip')\ndata[\"datetime\"] = pd.to_datetime(data[\"datetime\"], errors=\"coerce\")\ndf = (\n    data[data[\"country\"].str.lower() == \"us\"]\n    .dropna(subset=[\"datetime\", \"shape\"])\n    .copy()\n)\ndf[\"year\"] = df[\"datetime\"].dt.year\n\n# === Totals from 1990‚Äì2014 ===\ntotals = df.groupby(\"year\").size()\ntotals = totals[(totals.index &gt;= 1990) & (totals.index &lt;= 2014)]\n\n# === Shape pivot from 1990‚Äì2014 ===\nshape_counts_all = df.groupby([\"year\", \"shape\"]).size().unstack(fill_value=0)\nshape_counts_all = shape_counts_all[\n    (shape_counts_all.index &gt;= 1990) &\n    (shape_counts_all.index &lt;= 2014)\n]\n\n# === Top 5 shapes + ‚Äúuncommon shapes‚Äù ===\nshape_totals = shape_counts_all.sum().sort_values(ascending=False)\ntop_shapes    = shape_totals.head(5).index\nother_shapes  = shape_totals.index.difference(top_shapes)\n\nshape_counts = shape_counts_all[top_shapes].copy()\nshape_counts[\"uncommon shapes\"] = shape_counts_all[other_shapes].sum(axis=1)\n\n# === Prepare ColumnDataSource ===\nfinal_shapes = [\"uncommon shapes\"] + list(top_shapes)\nsource_data  = {\"year\": shape_counts.index.tolist()}\n#colors       = Category20[20][:len(final_shapes)]\ncolors = [\n    \"#f0ad4e\",  # yellow  ‚Üí \"uncommon shapes\"\n    \"#007bff\",  # blue    ‚Üí top shape 1\n    \"#fd7e14\",  # orange  ‚Üí top shape 2\n    \"#6f42c1\",  # purple  ‚Üí top shape 3\n    \"#d9534f\",   # red     ‚Üí top shape 5\n    \"#4bbf73\"  # green    ‚Üí top shape 4\n    \n]\nfor s in final_shapes:\n    source_data[s] = shape_counts[s].values\nsource = ColumnDataSource(source_data)\n\n# === Emoji map ===\nemoji_map = {\n    \"light\": \"üí°\", \"triangle\": \"üî∫\", \"circle\": \"‚≠ï\",\n    \"fireball\": \"üî•\", \"unknown\": \"‚ùì\", \"uncommon shapes\": \"üõ∏\"\n}\n\n# === Media events 1990‚Äì2014 ===\nmedia = {\n    1951: \"The Day the Earth Stood Still\",\n    1977: \"Close Encounters\", 1979: \"Alien\", 1982: \"E.T.\",\n    1986: \"Aliens\", 1993: \"The X-Files (TV)\", 1996: \"Independence Day\",\n    1998: \"X-Files: The Movie\", 2002: \"Signs\",\n    2009: \"District 9\", 2014: \"Edge of Tomorrow\"\n}\nmedia_years = [y for y in media if 1990 &lt;= y &lt;= 2014 and y in totals.index]\nmedia_source = ColumnDataSource(dict(\n    year =[y for y in media_years],\n    count=[totals[y] for y in media_years],\n    title=[media[y] for y in media_years]\n))\n\n# === Figure setup ===\np = figure(\n    width=640, height=400,\n    x_range=(1990, 2014),\n    y_range=(0, shape_counts.sum(axis=1).max() * 1.15),\n    background_fill_color=\"#f5f5f5\",\n    title=\"U.S. UFO Shape Distribution Over Time (1990‚Äì2014)\",\n    tools=\"\", toolbar_location=None\n)\n\n# === Stacked area ===\np.varea_stack(\n    stackers=final_shapes,\n    x=\"year\",\n    color=colors,\n    legend_label=[f\"{emoji_map[s]} {s}\" for s in final_shapes],\n    source=source\n)\np.legend.items = list(reversed(p.legend.items))\n\n# === Media event markers ===\nmedia_renderer = p.circle(\n    'year','count', source=media_source,\n    size=12, fill_color=\"#ffd700\", line_color=\"white\",\n    line_width=1.3, legend_label=\"Media Event\", level=\"overlay\"\n)\np.add_tools(HoverTool(\n    renderers=[media_renderer],\n    tooltips=[(\"Movie\", \"@title\"), (\"Year\",\"@year\"), (\"Sightings\",\"@count\")],\n    mode=\"mouse\", point_policy=\"follow_mouse\"\n))\n\n# === Emojis ===\nrecent = shape_counts.tail(25)\nmax_h  = recent.sum(axis=1).max()\nx_pts, y_pts, emojis, sizes = [], [], [], []\nfor i, s in enumerate(final_shapes):\n    yr    = recent[s].idxmax()\n    below = recent[final_shapes[:i]].loc[yr].sum()\n    band  = recent[s].loc[yr]\n    x_pts.append(yr)\n    y_pts.append(below + band/2)\n    emojis.append(emoji_map[s])\n    sizes.append(f\"{10 + band/max_h*16 - 4:.0f}pt\")\n\nemoji_source = ColumnDataSource(dict(x=x_pts, y=y_pts, emoji=emojis, size=sizes))\np.add_layout(LabelSet(\n    x='x', y='y', text='emoji', source=emoji_source,\n    text_font_size='size', text_align=\"center\", text_baseline=\"middle\"\n))\n\n# === Styling ===\np.xaxis.axis_label            = \"Year\"\np.yaxis.axis_label            = \"Sightings\"\np.xaxis.major_label_text_color = \"#000\"\np.yaxis.major_label_text_color = \"#000\"\np.xaxis.axis_line_color       = \"#000\"\np.yaxis.axis_line_color       = \"#000\"\np.xgrid.grid_line_color       = None\np.ygrid.grid_line_color       = \"#222244\"\np.title.text_color            = \"#000\"\np.title.text_font_size        = \"12pt\"\np.legend.label_text_color     = \"#000000\"\np.legend.background_fill_alpha=  1\np.legend.location             = \"top_left\"\np.legend.label_text_font_size = \"9pt\"\n\n# Show it\nshow(p)\n\n\n\n\n\n\n  \n\n\n\n\n\nFigure 1: Times series plot which shows the distribution of the different shapes and sightings, but also highlights some important dates in regards to media releases. There has been a rather large increase over the year. In particular after the realase of ‚Äúindependence day‚Äù and the the show x-files.\nTo more clearly see the distribution of the different shapes over the years we also look at a pie-chart.\n\n\nCode\nfrom bokeh.io import output_notebook, show\nfrom bokeh.plotting import figure\nfrom bokeh.models import ColumnDataSource, Slider, CustomJS, Div\nfrom bokeh.layouts import column, row\nimport pandas as pd\nimport numpy as np\nfrom math import pi, cos, sin\n\noutput_notebook(hide_banner=1)\n\n# === Load and preprocess data ===\ndf = pd.read_csv('data/complete.csv', on_bad_lines='skip', dtype=str)\ndf['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')\ndf = df.dropna(subset=['datetime'])\ndf['year'] = df['datetime'].dt.year.astype(int)\ndf['shape'] = df['shape'].fillna('UNKNOWN').str.upper()\ndf = df[(df['year'] &gt;= 1990) & (df['year'] &lt;= 2014)]\ndf = df[df['shape'] != 'OTHER']  # ‚úÖ REMOVE \"OTHER\" COMPLETELY\n\n# === Determine top shapes ===\nyears = list(range(1990, 2015))\ntop_shapes = set()\nfor y in years:\n    excluded_shapes = {'CIGAR', 'FORMATION',\"RECTANGLE\"}\n    cnts = df[(df['year'] == y) & (~df['shape'].isin(excluded_shapes))]['shape'].value_counts()\n    top_shapes |= set(cnts.index[:7])\ntop_shapes = sorted(top_shapes)\n\n# === Emoji & Color Map ===\nemoji_map = {\n    'CIRCLE': '‚≠ï',\n    'DISK': 'üíø',\n    'FIREBALL': 'üî•',\n    'LIGHT': 'üí°',\n    'OVAL': 'ü•ö',\n    'SPHERE': 'üîµ',\n    'TRIANGLE': 'üî∫',\n    'UNKNOWN': '‚ùì',\n    'Uncommon Shapes': 'üõ∏'\n}\n\n# ‚úÖ MANUAL COLOR ASSIGNMENT (customize here)\ncolor_map = {\n    'CIRCLE': \"#6610f2\",\n    'DISK': \"#1f9bcf\",\n    'FIREBALL': \"#d9534f\",\n    'LIGHT': \"#007bff\",\n    'OVAL': \"#6f42c1\",\n    'SPHERE': \"#20c997\",\n    'TRIANGLE': \"#fd7e14\",\n    'UNKNOWN': \"#4bbf73\",\n    'Uncommon Shapes': \"#f0ad4e\"\n}\n\n# === Prepare data per year ===\ndata_by_year = {}\nfor y in years:\n    cnts = df[df['year'] == y]['shape'].value_counts()\n    top7 = cnts.iloc[:7]\n    uncommon = cnts.iloc[7:].sum()\n    labels = list(top7.index)\n    values = list(top7.values)\n    if uncommon &gt; 0:\n        labels.append('Uncommon Shapes')\n        values.append(uncommon)\n    total = sum(values)\n\n    angles = [v / total * 2 * pi for v in values]\n    starts = np.cumsum([0] + angles[:-1])\n    ends = starts + angles\n    mids = starts + np.array(angles) / 2\n\n    x_inner = 0.6 * np.cos(mids)\n    y_inner = 1 + 0.6 * np.sin(mids)\n\n    pct_vals = [v / total * 100 for v in values]\n    emoji_pct = [\n        f\"{emoji_map.get(lbl, '')}\\n{p:.1f}%\" if p &gt;= 10 else f\"{emoji_map.get(lbl, '')}\"\n        for lbl, p in zip(labels, pct_vals)\n    ]\n\n    data_by_year[str(y)] = {\n        'start_angle': starts.tolist(),\n        'end_angle': ends.tolist(),\n        'color': [color_map.get(lbl, \"#cccccc\") for lbl in labels],\n        'emoji_pct': emoji_pct,\n        'x_inner': x_inner.tolist(),\n        'y_inner': y_inner.tolist(),\n        'label': labels\n    }\n\n# === Initial Year Setup ===\ninitial = years[0]\nsrc = ColumnDataSource(data_by_year[str(initial)])\n\n# === Figure ===\np = figure(height=460, width=458,\n           title=f\"UFO Shapes in {initial}\",\n           toolbar_location=None,\n           x_range=(-1.2, 1.2), y_range=(0, 2.4),background_fill_color=\"#f5f5f5\")\n\np.wedge(x=0, y=1, radius=0.9,\n        start_angle='start_angle', end_angle='end_angle',\n        fill_color='color', line_color='white',\n        source=src)\n\np.text(x='x_inner', y='y_inner', text='emoji_pct',\n       source=src,\n       text_align='center', text_baseline='middle',\n       text_font_size='12pt')\n\np.axis.visible = False\np.grid.visible = False\np.xaxis.axis_line_color= \"#333333\"\n# === Slider ===\nslider = Slider(start=years[0], end=years[-1], value=initial, step=1, title=\"Year\")\n\ncallback = CustomJS(args=dict(src=src, data_by_year=data_by_year, plot=p, slider=slider), code=\"\"\"\n    const yr = slider.value.toString();\n    const d = data_by_year[yr];\n    src.data = d;\n    plot.title.text = 'UFO Shapes in ' + yr;\n    src.change.emit();\n\"\"\")\nslider.js_on_change('value', callback)\n\n# === Legend as HTML (aligned beside the chart) ===\nlegend_html = \"&lt;div style='font-size: 14px; line-height: 1.6em;'&gt;\"\nfor shape in top_shapes + ['Uncommon Shapes']:\n    emoji = emoji_map.get(shape, '')\n    color = color_map.get(shape, '#999999')\n    label = shape.lower()\n    legend_html += f\"\"\"\n        &lt;div style=\"display: flex; align-items: center; gap: 8px; margin-bottom: 6px;\"&gt;\n            &lt;div style=\"width: 14px; height: 14px; background-color: {color}; border-radius: 3px; flex-shrink: 0;\"&gt;&lt;/div&gt;\n            &lt;span&gt;{emoji} {label}&lt;/span&gt;\n        &lt;/div&gt;\n    \"\"\"\nlegend_html += \"&lt;/div&gt;\"\nlegend_div = Div(text=f\"&lt;div style='margin-left:20px; margin-top:30px'&gt;{legend_html}&lt;/div&gt;\", width=160)\n\n# === Layout ===\nlayout = column(slider, row(p, legend_div))\nshow(layout)\n\n\n\n  \n\n\n\nFigure 2: The pie-chart shows the different shapes of the reported UFOs. Uncommon shapes means the sum of all the different shapes which are to few to be their own category and is therefore the biggest most of the time. But the real biggest category is light. This makes one suspect that a lot of the sightings may be from air craft.\nThe time-series plot above illustrates the number of reported UFO sightings in the United States from 1990 to 2014. Overall, there is a clear upward trend in the number of sightings over the years, peaking around 2012‚Äì2013. Notably, a sharp decline in sightings is observed after 2013. This drop is not necessarily indicative of a real-world change in UFO activity, but rather reflects the structure of the dataset, which ends around mid-September 2013. Thus, the apparent decline is primarily due to incomplete data.\nThe peak around 2012‚Äì2013 may be attributed to a combination of cultural and technological factors. According to an article in Astronomy titled ‚ÄúReports of rising UFO sightings are greatly exaggerated,‚Äù the widespread use of smartphone cameras without mechanical shutters may introduce image artifacts, such as blurring and smearing, which could contribute to mistaken sightings. Additionally, the ‚Äú2012 phenomenon‚Äù a widely circulated belief that the year 2012 would mark a significant transformation or apocalyptic event may have heightened public sensitivity and made individuals more prone to misinterpret ordinary visual stimuli as extraordinary. Beliefs surrounding Planet X, doomsday scenarios, and cosmic events likely amplified this effect, contributing to the surge in reported sightings during this period.\nThe plot also includes a frequency distribution of reported UFO shapes between 1990 and 2014. While most shapes appear consistently reported over time, there is a noticeable spike in reports of ‚Äúunknown‚Äù shapes around 1995. This anomaly suggests a temporary increase in sightings where witnesses were unable or unwilling to classify the object‚Äôs form, possibly due to ambiguity in observations or growing public discourse about UFOs during that period.\nTo understand the broader pattern of increasing sightings from the 1990s to the early 2010s, one must consider external societal trends. Data from the International Civil Aviation Organization (ICAO) suggest a steady increase in global air traffic, as indicated by rising Revenue Passenger-Kilometres (RPKs). Although the data do not directly reflect the number of flights, they imply a growing presence of aerial vehicles in the skies, which may increase the likelihood of misidentifying conventional aircraft as unidentified flying objects.\nAdditionally, the influence of pop culture is clearly visible. Markers on the time-series plot indicate the release of major alien-themed films, such as The X-Files and Independence Day. These releases coincide with noticeable spikes in UFO sightings, suggesting that media exposure may influence public perception and increase observational activity. This idea is supported by a CBC article titled ‚ÄúRecord British UFO sightings in 1990s,‚Äù which asserts that such media events raise public awareness and curiosity, leading to more frequent UFO reports. Kilder:\nhttps://www.astronomy.com/science/reports-of-rising-ufo-sightings-are-greatly-exaggerated/\nhttps://en.wikipedia.org/wiki/Nibiru_cataclysm (ift Planet X i 2012)\nhttps://www.icao.int/sustainability/pages/facts-figures_worldeconomydata.aspx\nhttps://www.cbc.ca/news/world/record-british-ufo-sightings-in-1990s-1.817993\n\n\n\n\n\nCode\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\ndata = pd.read_csv(\"data/complete.csv\", on_bad_lines='skip')\ndata['datetime'] = pd.to_datetime(data['datetime'], errors='coerce')\ndf=data[data[\"country\"]==\"us\"].sort_index(level=\"datetime\")\ndf = df.dropna(subset=['datetime'])\ndf = df.sort_values(by='datetime').reset_index(drop=True)\ndf=df.dropna()\n\nplt.figure().set_figwidth(7.5)\nax=plt.gca()\nplt.xticks(np.arange(0, 25, 1))\nax.set_facecolor(\"#f5f5f5\")\n\n\n#ax.xaxis.grid(False)\n#ax.grid(True,axis=\"y\", zorder=1)\nhourtime=df[\"time\"]=df[\"datetime\"].dt.hour\nplt.hist(hourtime, bins=24, range=(0, 24), density=0, color='#007bff',zorder=4)\nax.grid(True, axis=\"y\",linestyle='-', alpha=0.7,color=\"#222244\",zorder=0)\nplt.xlim(0,24)\nplt.xlabel('Hour of the Day')\nplt.show()\n\n\n\n\n\n\n\n\n\nFigure 3: This figure shows the the number of sightings per hour. It is clear that the sightings are mostly a thing of the evening/night. This also makes sense considering that a lot of the sigtings are light.\nWe‚Äôve now examined two theories attempting to explain the recent surge in UFO sightings. But what happens when we shift our focus to when these sightings occur throughout the day?\nAs shown in Figure 2, the majority of sightings are clustered between 20:00 and 24:00, with a noticeable peak at 22:00. Several factors might account for this trend. Referring back to Figure 1, we see that the most commonly reported UFO shape is simply described as ‚Äúlight.‚Äù This aligns neatly with what we might expect after all, the stark contrast between a dark night sky and any bright object makes such lights far more noticeable. It is the same principle, that makes stars visible at night.\nWhy 22:00 in particular? It appears to represent an optimal balance. By this hour, the sky is fully dark, providing ideal conditions for spotting shining objects against a dark backdrop. At the same time, it is still within a reasonable timeframe when many people are likely to be outdoors. In contrast, sightings tend to decline past midnight, likely due to reduced human presence and decreased observational activity during the early morning hours.\n\n\n\n\n\nCode\n# Where we have included the location of different military air force bases. It seems that there often are a lot of sightings around big cities which also sometimes have airforce bases. But sometimes places where there is only airforce bases also sees an increase in sightings\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom folium import plugins\nfrom folium.plugins import HeatMap\nimport folium\nfrom branca.element import Template, MacroElement\n\ndata = pd.read_csv(\"data/complete.csv\", on_bad_lines='skip')\ndata['datetime'] = pd.to_datetime(data['datetime'], errors='coerce')\ndf=data[data[\"country\"]==\"us\"].sort_index(level=\"datetime\")\ndf = df.dropna(subset=['datetime'])\ndf = df.sort_values(by='datetime').reset_index(drop=True)\ndf=df.dropna()\n\nmilbases=pd.read_csv(\"data/clean_military_bases.csv\")\nmilcomp=milbases[\"component\"]\nletters=[i[0:2] for i in milbases[\"component\"]]\n\nmilbases=milbases[(milcomp==\"AF Guard\" ) |(milcomp==\"AF Reserve\" )| (milcomp==\"AF Active\")]\n\nmilbasesl=milbases[[\"latitude\",\"longitude\"]]\n\n# Create your map\nmap_hooray = folium.Map(location=[40.80887462217925, -101.64736435756755], zoom_start=4)\n\n# Process your heatmap data\ndf['latitude'] = df['latitude'].astype(float)\ndf['longitude'] = df['longitude'].astype(float)\nheat_df = df[['latitude', 'longitude']].dropna()\nheat_data = [[row['latitude'], row['longitude']] for index, row in heat_df.iterrows()]\n\n# Add heatmap with adjusted parameters for less density\nHeatMap(\n    heat_data,\n    radius=5,             # smaller spread\n    blur=1,               # smoother blending\n    max_opacity=0.5,       # reduce color saturation\n    min_opacity=0.3,       # allow fade for low-density areas\n    use_local_extrema=False  # keep global scale\n).add_to(map_hooray)\n\n# Add circle markers for different components\nfor index, row in milbasesl[milcomp == \"AF Reserve\"].iterrows():\n    folium.CircleMarker(\n        location=[row['latitude'], row['longitude']],\n        radius=3,\n        color='#6610f2',\n        fill=True,\n        fill_color='#6610f2',\n        fill_opacity=0.6\n    ).add_to(map_hooray)\n\nfor index, row in milbasesl[milcomp == \"AF Active\"].iterrows():\n    folium.CircleMarker(\n        location=[row['latitude'], row['longitude']],\n        radius=3,\n        color='#007bff',\n        fill=True,\n        fill_color='#007bff',\n        fill_opacity=0.6\n    ).add_to(map_hooray)\n\nfor index, row in milbasesl[milcomp == \"AF Guard\"].iterrows():\n    folium.CircleMarker(\n        location=[row['latitude'], row['longitude']],\n        radius=3,\n        color='#09772f',\n        fill=True,\n        fill_color='#09772f',\n        fill_opacity=0.6\n    ).add_to(map_hooray)\n\n# Custom legend (unchanged)\ntemplate = \"\"\"\n{% macro html(this, kwargs) %}\n&lt;!doctype html&gt;\n&lt;html lang=\"en\"&gt;\n&lt;head&gt;\n  &lt;meta charset=\"utf-8\"&gt;\n  &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"&gt;\n  &lt;title&gt;Heatmap Legend&lt;/title&gt;\n  &lt;link rel=\"stylesheet\" href=\"//code.jquery.com/ui/1.12.1/themes/base/jquery-ui.css\"&gt;\n  &lt;script src=\"https://code.jquery.com/jquery-1.12.4.js\"&gt;&lt;/script&gt;\n  &lt;script src=\"https://code.jquery.com/ui/1.12.1/jquery-ui.js\"&gt;&lt;/script&gt;\n  &lt;script&gt;\n  $( function() {\n    $( \"#maplegend\" ).draggable({\n        start: function (event, ui) {\n            $(this).css({ right: \"auto\", top: \"auto\", bottom: \"auto\" });\n        }\n    });\n  });\n  &lt;/script&gt;\n&lt;/head&gt;\n&lt;body&gt;\n&lt;div id='maplegend' class='maplegend' \n    style='position: absolute; z-index:9999; border:2px solid grey; background-color:rgba(255, 255, 255, 0.8);\n     border-radius:6px; padding: 10px; font-size:14px; right: 20px; bottom: 20px;'&gt;\n     \n&lt;div class='legend-title'&gt;Legend&lt;/div&gt;\n&lt;div class='legend-scale'&gt;\n  &lt;ul class='legend-labels'&gt;\n    &lt;li&gt;&lt;span style='background:#6610f2;opacity:0.7;'&gt;&lt;/span&gt;AF Active&lt;/li&gt;\n    &lt;li&gt;&lt;span style='background:#007bff;opacity:0.7;'&gt;&lt;/span&gt;AF Reserve&lt;/li&gt;\n    &lt;li&gt;&lt;span style='background:#09772f;opacity:0.7;'&gt;&lt;/span&gt;AF Guard&lt;/li&gt;\n  &lt;/ul&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n\n&lt;style type='text/css'&gt;\n  .maplegend .legend-title {\n    text-align: left;\n    margin-bottom: 5px;\n    font-weight: bold;\n    font-size: 90%;\n    }\n  .maplegend .legend-scale ul {\n    margin: 0;\n    padding: 0;\n    float: left;\n    list-style: none;\n    }\n  .maplegend .legend-scale ul li {\n    font-size: 80%;\n    list-style: none;\n    margin-left: 0;\n    line-height: 18px;\n    margin-bottom: 2px;\n    }\n  .maplegend ul.legend-labels li span {\n    display: block;\n    float: left;\n    height: 16px;\n    width: 30px;\n    margin-right: 5px;\n    margin-left: 0;\n    border: 1px solid #999;\n    }\n  .maplegend .legend-source {\n    font-size: 80%;\n    color: #777;\n    clear: both;\n    }\n  .maplegend a {\n    color: #777;\n    }\n&lt;/style&gt;\n{% endmacro %}\n\"\"\"\n\n# Add the legend to the map\nmacro = MacroElement()\nmacro._template = Template(template)\nmap_hooray.get_root().add_child(macro)\n\n# Display the map\nmap_hooray\n\n\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\nFigure¬†1\n\n\n\n\nNow we want to explore a different angle, we therefore wish to plot the geographical data. This results in a heat map. Along with the sighting distribution the heat map also contains airforce bases, in order to explore Air Force flights influence on UFO sightings. The heat map will only contain Air Force bases, despite other branches of the U.S Military containing aircraft, due to simplicity as it would be impossible to distinguish between an Army Airbase, and an regular infantry base.\nFigure 3 reveals a clear pattern: regions in proximity to active airbases tend to exhibit a high density of UFO sightings. One plausible explanation is that these sightings may, in fact, correspond to military aircraft activity. Given that military aircraft are routinely operated near their bases regardless of weather conditions or time of day it is not unreasonable to assume that experimental or unfamiliar aircraft flying at night could be mistaken for unidentified flying objects by unsuspecting observers. Since airbases are geographically fixed, such misidentifications would naturally accumulate in the same locations over time, resulting in noticeable clusters of sightings.\nAnother notable observation from Figure 3 is the clear disparity in the density and distribution of UFO sightings between the eastern and western regions of the United States. Sightings appear to be significantly more frequent in the east, where high density areas form a nearly continuous band across much of the region. This pattern is especially pronounced around major metropolitan centers such as New York, Chicago, and Washington, D.C, where sightings are heavily clustered. In contrast, the western United States shows a markedly different pattern. Sightings in this region are largely confined to the coasts and major urban centers, including cities like Los Angeles and San Francisco. Vast interior areas of the west, including parts of the Rocky Mountains and Great Basin, exhibit little to no reported activity.\nWe suspect the reason between this great disparity, is most likely population size and density. As we mentioned two large areas of the west ie. The Rocky Mountains and Great Basin has almost no sightings reported. These two areas are also very sparsely populated, while coastal and urban centers such as Los Angeles, San Francisco, Seattle, Salt Lake City and Denver still report large amounts of sightings. This could indicate that reported UFO sightings are correlated with population size.\n** There is also something to talk about in regards to low populated states having spikes in sigighings **\n\n\n\nWe want to investigate if there is this correlation between\n\n\nCode\nimport pandas as pd\nfrom bokeh.plotting import figure, show, output_notebook\nfrom bokeh.models import ColumnDataSource, CustomJS, HoverTool, TapTool\nfrom bokeh.palettes import viridis\n\noutput_notebook(hide_banner=1)\n\nexcluded = {'pr', 'dc'}\n\n# Load and clean population data\ndata = pd.read_csv(\"data/historical_state_population_by_year.csv\", on_bad_lines='skip')\ndata = data[(data['year'] &gt;= 1950) & (data['year'] &lt;= 2014)]\ndata[\"state\"] = data[\"state\"].str.lower()\ndata = data[data[\"state\"].isin(excluded) == False]\ndata = data.dropna(subset=['state'])\n\n# Load and clean UFO data\ndf = pd.read_csv(\"data/complete.csv\", on_bad_lines='skip')\ndf['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')\ndf = df[df[\"country\"] == \"us\"]\ndf = df[df[\"state\"].isin(excluded) == False]\ndf = df.dropna(subset=['datetime'])\ndf['year'] = df['datetime'].dt.year\ndf = df[(df['year'] &gt;= 1950) & (df['year'] &lt;= 2014)]\n\n# Group and merge\ngrouped = df.groupby(['state', 'year']).size().reset_index(name='num_sightings')\nall_states = sorted(df['state'].unique())\nall_years = range(1950, 2015)\nfull_index = pd.MultiIndex.from_product([all_states, all_years], names=['state', 'year'])\nsightings_summary = grouped.set_index(['state', 'year']).reindex(full_index, fill_value=0).reset_index()\nmerged = pd.merge(data, sightings_summary, on=['state', 'year']).dropna(subset=['population', 'num_sightings'])\nmerged['population'] = merged['population'] / 1_000_000\n# Use a colorblind-friendly palette\ncolorblind_palette = [\n    \"#007bff\",  # blue\n    \"#6610f2\",  # indigo\n    \"#6f42c1\",  # purple\n    \"#e83e8c\",  # pink\n    \"#d9534f\",  # red\n    \"#fd7e14\",  # orange\n    \"#f0ad4e\",  # yellow\n    \"#4bbf73\",  # green\n    \"#20c997\",  # teal\n    \"#1f9bcf\"   # cyan\n]\n\nextended_palette = (colorblind_palette * ((len(all_states) // len(colorblind_palette)) + 1))[:len(all_states)]\nstate_color_map = dict(zip(all_states, extended_palette))\n\nmerged['color'] = merged['state'].map(state_color_map)\nmerged['alpha'] = [0.6] * len(merged)\n\nsource = ColumnDataSource(merged)\n\n# Plot setup\np = figure(title=\"UFO Sightings vs Population (1950‚Äì2014)\",\n           x_axis_label=\"Population\", y_axis_label=\"Number of Sightings\",\n           tools=\"pan,wheel_zoom,box_zoom,reset,tap,hover\",\n           width=640, height=600,background_fill_color=\"#f5f5f5\")\n\n# Draw points\np.circle('population', 'num_sightings',\n         source=source,\n         size=6,\n         color='color',\n         alpha='alpha',\n         line_color=None)\n\n# Hover tool: passive inspection\nhover = p.select_one(HoverTool)\nhover.tooltips = [\n    (\"State\", \"@state\"),\n    (\"Year\", \"@year\"),\n    (\"Population\", \"@population{0,0}\"),\n    (\"Sightings\", \"@num_sightings\")\n]\n\n# Tap tool: highlights all from the clicked state\ntap_callback = CustomJS(args=dict(source=source), code=\"\"\"\n    const selected = source.selected.indices[0];\n    const data = source.data;\n    const N = data['state'].length;\n\n    if (selected == null) return;\n\n    const selected_state = data['state'][selected];\n\n    for (let i = 0; i &lt; N; i++) {\n        data['alpha'][i] = (data['state'][i] === selected_state) ? 1.0 : 0.1;\n    }\n    source.change.emit();\n\"\"\")\n\ntaptool = p.select_one(TapTool)\ntaptool.callback = tap_callback\n\nshow(p)\n\n\n\n\n\n\n\n\n\n\n(a) A chart which shows the UFO sightings over population over the last from 1950 to 2014. The different states are highligthed with different colors. One sees that there is a lot of smaller populations which does not have that many sightings. One also sees that some states have seen a major increase in sigthings even though there population remained rather stable\n\n\n\n\n\n\n\n  \n\n\n(b)\n\n\n\n\n\n\n\n\n\n(c)\n\n\n\n\n\nFigure¬†2\n\n\n\n\n\n\nCode\nfrom bokeh.io import output_notebook, show\nfrom bokeh.plotting import figure\nfrom bokeh.models import ColumnDataSource, Slider, CustomJS\nfrom bokeh.layouts import column\nfrom sklearn.linear_model import LinearRegression\nimport pandas as pd\nimport numpy as np\nimport json\n\noutput_notebook(hide_banner=True)\n\n# Load and clean population data\nexcluded = {'pr', 'dc'}\ndata = pd.read_csv(\"data/historical_state_population_by_year.csv\", on_bad_lines='skip')\ndata = data[(data['year'] &gt;= 1950) & (data['year'] &lt;= 2014)]\ndata[\"state\"] = data[\"state\"].str.lower()\ndata = data[~data[\"state\"].isin(excluded)]\ndata = data.dropna(subset=['state'])\n\n# Load and clean sightings data\ndf = pd.read_csv(\"data/complete.csv\", on_bad_lines='skip')\ndf['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')\ndf = df[df[\"country\"] == \"us\"]\ndf = df[~df[\"state\"].isin(excluded)]\ndf = df.dropna(subset=['datetime'])\ndf = df.sort_values(by='datetime').reset_index(drop=True)\ndf['year'] = df['datetime'].dt.year\ndf = df[(df['year'] &gt;= 1950) & (df['year'] &lt;= 2014)]\n\n# Group by state and year\ngrouped = df.groupby(['state', 'year']).size().reset_index(name='num_sightings')\n\n# Create complete grid\nall_states = df['state'].unique()\nall_years = range(1950, 2015)\nfull_index = pd.MultiIndex.from_product([all_states, all_years], names=['state', 'year'])\nsightings_summary = grouped.set_index(['state', 'year']).reindex(full_index, fill_value=0).reset_index()\n\n# Merge datasets\nmerged = pd.merge(data, sightings_summary, on=['year', 'state'])\n\n# Compute correlation per year\nstate_correlations = merged.groupby('year').apply(\n    lambda g: g['population'].corr(g['num_sightings'])\n).reset_index(name='correlation')\n\n# Prepare Bokeh data structures\nyear_data = {}\nplot_meta = {}\n\nfor year in sorted(merged['year'].unique()):\n    df_year = merged[merged['year'] == year]\n    x = df_year['population'].values/1000000\n    y = df_year['num_sightings'].values\n\n    if len(x) &gt; 1:\n        model = LinearRegression()\n        model.fit(x.reshape(-1, 1), y)\n        y_pred = model.predict(x.reshape(-1, 1))\n        slope = model.coef_[0]\n        intercept = model.intercept_\n        ss_res = np.sum((y - y_pred) ** 2)\n        ss_tot = np.sum((y - np.mean(y)) ** 2)\n        r2 = 1 - ss_res / ss_tot\n    else:\n        y_pred = np.zeros_like(x)\n        slope = intercept = r2 = 0\n\n    corr = state_correlations[state_correlations['year'] == year]['correlation'].values[0]\n\n    year_data[str(year)] = {\n        'x': x.tolist(),\n        'y': y.tolist(),\n        'y_pred': y_pred.tolist()\n    }\n\n    plot_meta[str(year)] = {\n        'title': f\"UFO Sightings vs Population - {year} | Correlation = {corr:.2f}\"\n    }\n\n# Bokeh plotting\ninitial_year = \"1987\"\nsource = ColumnDataSource(data=year_data[initial_year])\n\np = figure(height=400, width=640,\n           title=plot_meta[initial_year]['title'],\n           x_axis_label='Population (per milion)', y_axis_label='Number of Sightings',background_fill_color=\"#f5f5f5\")\n\np.circle('x', 'y', size=8, source=source,color=\"#007bff\")\np.line('x', 'y_pred', source=source, line_width=2, \ncolor='#d9534f')\n\n#p.legend.location = \"top_left\"\n\n# Slider and JS Callback\nslider = Slider(start=merged['year'].min(), end=merged['year'].max(), value=int(initial_year), step=1, title=\"Year\")\n\ncallback = CustomJS(args=dict(source=source, slider=slider, plot=p),\n    code=f\"\"\"\n        const year_data = {json.dumps(year_data)};\n        const meta = {json.dumps(plot_meta)};\n        const year = slider.value.toString();\n\n        source.data = year_data[year];\n        plot.title.text = meta[year].title;\n        source.change.emit();\n    \"\"\"\n)\n\nslider.js_on_change('value', callback)\n\nshow(column(slider, p))\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n  \n\n\n(b)\n\n\n\n\n\n\n\n\n\n(c)\n\n\n\n\n\nFigure¬†3\n\n\n\n\nAn examination of Figures 4 and 5 supports the hypothesis that reported UFO sightings are positively correlated with population size. This relationship is most evident in the year 2008, which shows the highest correlation coefficient of 0.96 between state population and the number of reported sightings. In contrast, the year 1951 exhibits the lowest correlation, with a coefficient of just 0.34. Overall, the early years of the dataset, particularly the first two decades, display a relatively weak correlation between population and sightings. However, beginning in the 1970s, the correlation becomes significantly stronger and more consistent.\nThis trend may be attributed to the growing influence of popular culture during that time. The 1970s marked a rise in public interest in UFOs and extraterrestrial life, largely driven by the emergence of films, television shows, and books that featured such themes. As these topics entered mainstream entertainment, public awareness and curiosity about UFOs likely increased. Moreover, the depiction of UFO sightings in media may have contributed to a gradual reduction in the stigma or taboo associated with reporting such events.\nIt is plausible that in the earlier decades, individuals were more hesitant to report sightings due to fear of ridicule or disbelief. As cultural perceptions shifted and UFO phenomena became more widely discussed and accepted, people may have felt more comfortable coming forward with their observations. Thus, the strengthening correlation over time could reflect not only population growth but also a growing willingness to report sightings, influenced by evolving social and cultural attitudes.\nThe previously mentioned factors help explain the overall increase in reported UFO sightings but do not fully account for the growing correlation between population size and sightings over time. To better understand this trend, it is useful to consider how observation conditions vary with geography. Interestingly, some of the best locations in the United States for observing the night sky are in sparsely populated areas, particularly in the western region. According to World Atlas (https://www.worldatlas.com/places/the-best-us-locations-for-unobstructed-night-sky-viewing.html), four out of the six top-rated stargazing locations in the U.S. are in the West, with many of them situated in desert environments. These areas offer minimal light pollution and clear, unobstructed skies ideal conditions for observing aerial activity.\nThis suggests that in the earlier decades of the dataset, sightings may have been more likely to occur in these open and remote areas, where sky visibility is optimal but population density is low. As a result, even though sightings occurred, they were less frequent overall and less likely to be reported or to reflect population trends. Over time, as public interest in UFOs increased and reporting became more socially acceptable, sightings in more populated areas began to rise, thereby increasing the observed correlation with population. Thus, the shift in both where and how often people reported sightings may explain the growing alignment between population size and UFO sighting frequency."
  },
  {
    "objectID": "Plots/correlation.html",
    "href": "Plots/correlation.html",
    "title": "Social data analysis and visualization project",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nexcluded = {'pr', 'dc'}\n\ndata = pd.read_csv(\"../data/historical_state_population_by_year.csv\", on_bad_lines='skip')\ndata = data[(data['year'] &gt;= 1950) & (data['year'] &lt;= 2014)]\ndata[\"state\"]=data[\"state\"].str.lower()\n\n# Filter out non-states\ndata[\"state\"]=data[\"state\"][data[\"state\"].isin(excluded)==False]\ndata = data.dropna(subset=['state'])\n\n\n\ndf = pd.read_csv(\"../data/complete.csv\", on_bad_lines='skip')\ndf['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')\ndf=df[df[\"country\"]==\"us\"].sort_index(level=\"datetime\")\ndf[\"state\"]=df[\"state\"][df[\"state\"].isin(excluded)==False]\ndf = df.dropna(subset=['datetime'])\ndf = df.sort_values(by='datetime').reset_index(drop=True)\ndf=df.dropna()\ndf['year'] = df['datetime'].dt.year\ndf = df[(df['year'] &gt;= 1950) & (df['year'] &lt;= 2014)]\n\n# Group by state and year\ngrouped = df.groupby(['state', 'year']).size().reset_index(name='num_sightings')\n\n# Create complete state-year grid\nall_states = df['state'].unique()\nall_years = range(1950, 2015)\nfull_index = pd.MultiIndex.from_product([all_states, all_years], names=['state', 'year'])\n\n# Reindex to include all combinations, fill missing with 0\nsightings_summary = grouped.set_index(['state', 'year']).reindex(full_index, fill_value=0).reset_index()\nsightings_summary = sightings_summary.sort_values(by=['state', 'year']).reset_index(drop=True)\n\nC:\\Users\\anton\\AppData\\Local\\Temp\\ipykernel_96532\\711170306.py:17: DtypeWarning: Columns (5,9) have mixed types. Specify dtype option on import or set low_memory=False.\n  df = pd.read_csv(\"../data/complete.csv\", on_bad_lines='skip')\n\n\n\nsightings_summary.head()\n\n\n\n\n\n\n\n\nstate\nyear\nnum_sightings\n\n\n\n\n0\nak\n1950\n0\n\n\n1\nak\n1951\n0\n\n\n2\nak\n1952\n0\n\n\n3\nak\n1953\n0\n\n\n4\nak\n1954\n1\n\n\n\n\n\n\n\n\ndata.head()\n\n\n\n\n\n\n\n\nstate\nyear\npopulation\n\n\n\n\n0\nak\n1950\n135000\n\n\n1\nak\n1951\n158000\n\n\n2\nak\n1952\n189000\n\n\n3\nak\n1953\n205000\n\n\n4\nak\n1954\n215000\n\n\n\n\n\n\n\n\nmerged = pd.merge(data, sightings_summary, on=['state', 'year'])\n\n# Drop any rows with missing data (just in case)\nmerged = merged.dropna(subset=['population', 'num_sightings'])\n\n# Calculate correlation\ncorrelation = merged['population'].corr(merged['num_sightings'])\ncorrelation\n\n0.5696297006636651\n\n\n\nplt.scatter(data[\"population\"], sightings_summary[\"num_sightings\"], label=\"Population\")\nplt.title('UFO Sightings vs Population (1950‚Äì2014)')\nplt.xlabel('Population')\nplt.ylabel('Number of Sightings')\n#plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize='small', ncol=2)\nplt.tight_layout()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\nsightings_summary\n\n\n\n\n\n\n\n\nstate\nyear\nnum_sightings\n\n\n\n\n0\nak\n1950\n0\n\n\n1\nak\n1951\n0\n\n\n2\nak\n1952\n0\n\n\n3\nak\n1953\n0\n\n\n4\nak\n1954\n1\n\n\n...\n...\n...\n...\n\n\n3245\nwy\n2010\n11\n\n\n3246\nwy\n2011\n17\n\n\n3247\nwy\n2012\n12\n\n\n3248\nwy\n2013\n13\n\n\n3249\nwy\n2014\n3\n\n\n\n\n3250 rows √ó 3 columns\n\n\n\n\ndummyyear = 2008\nsightings_summary[\"num_sightings\"][sightings_summary[\"year\"]==dummyyear]\n\n58       10\n123      46\n188      32\n253     153\n318     630\n383      92\n448      52\n513       9\n578     265\n643      95\n708      12\n773      31\n838      19\n903     146\n968     111\n1033     26\n1098     62\n1163     40\n1228     66\n1293     54\n1358     22\n1423    121\n1488     49\n1553     92\n1618     18\n1683     17\n1748    121\n1813      9\n1878     15\n1943     31\n2008     78\n2073     50\n2138     58\n2203    185\n2268    121\n2333     51\n2398     80\n2463    159\n2528     16\n2593     37\n2658      7\n2723     86\n2788    336\n2853     24\n2918     88\n2983      9\n3048    179\n3113     59\n3178     26\n3243      8\nName: num_sightings, dtype: int64\n\n\n\ndummyyear = 2008\n#cumsom=sum(sightings_summary[\"num_sightings\"][sightings_summary[\"year\"]==dummyyear])\nplt.scatter(data[\"population\"][data[\"year\"]==dummyyear], sightings_summary[\"num_sightings\"][sightings_summary[\"year\"]==dummyyear], label=\"Population\")\nplt.title('UFO Sightings vs Population year 'f\"{dummyyear}\")\nplt.xlabel('Population')\nplt.ylabel('Number of Sightings')\n#plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize='small', ncol=2)\nplt.tight_layout()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom ipywidgets import interact, IntSlider\nfrom sklearn.linear_model import LinearRegression\nimport numpy as np\n\n# Assuming data and sightings_summary are pandas DataFrames\n\ndef plot_ufo_vs_population(dummyyear):\n    # Filter the data for the selected year\n    x = data[\"population\"][data[\"year\"] == dummyyear].values.reshape(-1, 1)\n    y = sightings_summary[\"num_sightings\"][sightings_summary[\"year\"] == dummyyear].values\n\n    # Check if there are enough points to fit a model\n    if len(x) &gt; 1 and len(y) &gt; 1:\n        model = LinearRegression()\n        model.fit(x, y)\n        slope = model.coef_[0]\n        y_pred = model.predict(x)\n    else:\n        slope = None\n        y_pred = None\n\n    # Plot\n    plt.figure(figsize=(8, 5))\n    plt.scatter(x, y, label=\"Population vs Sightings\")\n    \n    if slope is not None:\n        plt.plot(x, y_pred, color='red', label=f\"Fit: slope = {slope:.2f}\")\n    \n    plt.title(f'UFO Sightings vs Population - Year {dummyyear}')\n    plt.xlabel('Population')\n    plt.ylabel('Number of Sightings')\n    plt.grid(True)\n    plt.legend()\n    plt.tight_layout()\n    plt.show()\n\n# Create interactive slider from the available years\ninteract(plot_ufo_vs_population, dummyyear=IntSlider(min=data[\"year\"].min(), max=data[\"year\"].max(), step=1, value=2008))\n\n\n\n\n&lt;function __main__.plot_ufo_vs_population(dummyyear)&gt;\n\n\n\nplt.figure(figsize=(10, 6))\n\n# Plot each state as a different color\nfor state in merged['state'].unique():\n    state_data = merged[merged['state'] == state]\n    plt.scatter(state_data['population'], state_data['num_sightings'], label=state, alpha=0.6, s=20)\n\nplt.title('UFO Sightings vs Population (1950‚Äì2014)')\nplt.xlabel('Population')\nplt.ylabel('Number of Sightings')\nplt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize='small', ncol=2)\nplt.tight_layout()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\nfrom bokeh.io import output_notebook, show\nfrom bokeh.plotting import figure\nfrom bokeh.models import ColumnDataSource, Slider, CustomJS\nfrom bokeh.layouts import column\nfrom sklearn.linear_model import LinearRegression\nimport pandas as pd\nimport numpy as np\nimport json\n\noutput_notebook()\n\n# Assuming your merged dataset is already available\n# data = ...\n# sightings_summary = ...\n\n# Merge the data\nmerged = pd.merge(data, sightings_summary, on=['year', 'state'])\n\n# Calculate correlation for each year\nstate_correlations = merged.groupby('year').apply(\n    lambda g: g['population'].corr(g['num_sightings'])\n).reset_index(name='correlation')\n\n# Prepare data and metadata\nyear_data = {}\nplot_meta = {}\n\nfor year in sorted(merged['year'].unique()):\n    df = merged[merged['year'] == year]\n    x = df['population'].values\n    y = df['num_sightings'].values\n    if len(x) &gt; 1:\n        model = LinearRegression()\n        model.fit(x.reshape(-1, 1), y)\n        y_pred = model.predict(x.reshape(-1, 1))\n\n        # Calculate R^2\n        ss_res = np.sum((y - y_pred) ** 2)  # residual sum of squares\n        ss_tot = np.sum((y - np.mean(y)) ** 2)  # total sum of squares\n        r2 = 1 - (ss_res / ss_tot)\n\n        slope = model.coef_[0]\n        intercept = model.intercept_\n    else:\n        y_pred = np.zeros_like(x)\n        slope = 0\n        intercept = 0\n        r2 = 0  # Not enough data for meaningful R¬≤ calculation\n\n    # Get correlation for the current year\n    correlation = state_correlations[state_correlations['year'] == year]['correlation'].values[0]\n\n    # Save regression data\n    year_data[str(year)] = {\n        'x': x.tolist(),\n        'y': y.tolist(),\n        'y_pred': y_pred.tolist()\n    }\n\n    plot_meta[str(year)] = {\n        'title': f\"UFO Sightings vs Population - {year} | y = {slope:.2f}x + {intercept:.2f} | R¬≤ = {r2:.2f} | Correlation = {correlation:.2f}\"\n    }\n\n# Convert to JSON\nyear_data_json = json.dumps(year_data)\nplot_meta_json = json.dumps(plot_meta)\n\n# Initial year\ninitial_year = str(sorted(merged['year'].unique())[0])\nsource = ColumnDataSource(data=year_data[initial_year])\n\n# Create plot\np = figure(height=400, width=600,\n           title=plot_meta[initial_year]['title'],\n           x_axis_label='Population', y_axis_label='Number of Sightings')\n\np.circle('x', 'y', size=8, source=source, legend_label=\"Data\")\np.line('x', 'y_pred', source=source, line_width=2, color='red', legend_label=\"Regression Line\")\np.legend.location = \"top_left\"\n\n# Slider\nslider = Slider(start=merged['year'].min(), end=merged['year'].max(),\n                value=int(initial_year), step=1, title=\"Year\")\n\n# JavaScript callback\ncallback = CustomJS(args=dict(source=source, slider=slider, plot=p),\n    code=f\"\"\"\n    const year_data = {year_data_json};\n    const meta = {plot_meta_json};\n    const year = slider.value.toString();\n\n    source.data = year_data[year];\n    plot.title.text = meta[year].title;\n    source.change.emit();\n\"\"\")\n\nslider.js_on_change('value', callback)\n\n# Show layout\nshow(column(slider, p))\n\n    \n    \n        \n        Loading BokehJS ...\n    \n\n\n\n\n\nC:\\Users\\anton\\AppData\\Local\\Temp\\ipykernel_96532\\2972733765.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  state_correlations = merged.groupby('year').apply(\nBokehDeprecationWarning: 'circle() method with size value' was deprecated in Bokeh 3.4.0 and will be removed, use 'scatter(size=...) instead' instead.\n\n\n\n  \n\n\n\n\n\n\nplt.figure(figsize=(10, 6))\n\n# Plot each state as a different color\nfor state in merged['year'].unique():\n    state_data = merged[merged['year'] == state]\n    plt.scatter(state_data['population'], state_data['num_sightings'], label=state, alpha=0.6, s=20)\n\nplt.title('UFO Sightings vs Population (1950‚Äì2014)')\nplt.xlabel('Population')\nplt.ylabel('Number of Sightings')\nplt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize='small', ncol=2)\nplt.tight_layout()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n# Group by state and calculate correlation for each\nstate_correlations = merged.groupby('year').apply(\n    lambda g: g['population'].corr(g['num_sightings'])\n).reset_index(name='correlation')\n\n# Sort by correlation value\nstate_correlations = state_correlations.sort_values(by='correlation', ascending=False).reset_index(drop=True)\n\n# Display top results\nprint(state_correlations.head(10),state_correlations.tail(10))\nprint(state_correlations[state_correlations[\"year\"]==2012])\n\n   year  correlation\n0  2008     0.955354\n1  2009     0.932136\n2  1979     0.923227\n3  2007     0.918518\n4  2011     0.917496\n5  2006     0.917415\n6  1992     0.914901\n7  2010     0.910760\n8  2005     0.904767\n9  1988     0.901358     year  correlation\n55  1960     0.683100\n56  1955     0.678583\n57  1961     0.666662\n58  1964     0.642008\n59  1956     0.588274\n60  1952     0.576766\n61  1958     0.506954\n62  1950     0.407323\n63  1953     0.398800\n64  1951     0.344866\n    year  correlation\n11  2012     0.890528\n\n\nC:\\Users\\anton\\AppData\\Local\\Temp\\ipykernel_96532\\658423093.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  state_correlations = merged.groupby('year').apply(\n\n\n\nfrom bokeh.io import output_notebook, show\nfrom bokeh.plotting import figure\nfrom bokeh.models import ColumnDataSource, Slider, CustomJS\nfrom bokeh.layouts import column\nfrom sklearn.linear_model import LinearRegression\nimport pandas as pd\nimport numpy as np\nimport json\n\noutput_notebook()\n\n# Use your real data here\n# data = ...\n# sightings_summary = ...\n\n# Merge data\nmerged = pd.merge(data, sightings_summary, on=['year', 'state'])\n\n# Prepare data and metadata\nyear_data = {}\nplot_meta = {}\n\nfor year in sorted(merged['year'].unique()):\n    df = merged[merged['year'] == year]\n    x = df['population'].values\n    y = df['num_sightings'].values\n    if len(x) &gt; 1:\n        model = LinearRegression()\n        model.fit(x.reshape(-1, 1), y)\n        y_pred = model.predict(x.reshape(-1, 1))\n\n        # Calculate R^2\n        ss_res = np.sum((y - y_pred) ** 2)  # residual sum of squares\n        ss_tot = np.sum((y - np.mean(y)) ** 2)  # total sum of squares\n        r2 = 1 - (ss_res / ss_tot)\n\n        slope = model.coef_[0]\n        intercept = model.intercept_\n    else:\n        y_pred = np.zeros_like(x)\n        slope = 0\n        intercept = 0\n        r2 = 0  # Not enough data for meaningful R¬≤ calculation\n\n    # Save regression data\n    year_data[str(year)] = {\n        'x': x.tolist(),\n        'y': y.tolist(),\n        'y_pred': y_pred.tolist()\n    }\n\n    plot_meta[str(year)] = {\n        'title': f\"UFO Sightings vs Population - {year} | y = {slope:.2f}x + {intercept:.2f} | R¬≤ = {r2:.2f}\"\n    }\n\n# Convert to JSON\nyear_data_json = json.dumps(year_data)\nplot_meta_json = json.dumps(plot_meta)\n\n# Initial year\ninitial_year = str(sorted(merged['year'].unique())[0])\nsource = ColumnDataSource(data=year_data[initial_year])\n\n# Create plot\np = figure(height=400, width=600,\n           title=plot_meta[initial_year]['title'],\n           x_axis_label='Population', y_axis_label='Number of Sightings')\n\np.circle('x', 'y', size=8, source=source, legend_label=\"Data\")\np.line('x', 'y_pred', source=source, line_width=2, color='red', legend_label=\"Regression Line\")\np.legend.location = \"top_left\"\n\n# Slider\nslider = Slider(start=merged['year'].min(), end=merged['year'].max(),\n                value=int(initial_year), step=1, title=\"Year\")\n\n# JavaScript callback\ncallback = CustomJS(args=dict(source=source, slider=slider, plot=p),\n    code=f\"\"\"\n    const year_data = {year_data_json};\n    const meta = {plot_meta_json};\n    const year = slider.value.toString();\n\n    source.data = year_data[year];\n    plot.title.text = meta[year].title;\n    source.change.emit();\n\"\"\")\n\nslider.js_on_change('value', callback)\n\n# Show layout\nshow(column(slider, p))\n\n    \n    \n        \n        Loading BokehJS ...\n    \n\n\n\n\n\nBokehDeprecationWarning: 'circle() method with size value' was deprecated in Bokeh 3.4.0 and will be removed, use 'scatter(size=...) instead' instead.\n\n\n\n  \n\n\n\n\n\n\nchosen_state = 'ca'  # Replace with any valid state abbreviation in lowercase\n\n# Filter the data for that state\nstate_data = merged[merged['state'] == chosen_state]\n\n# Plot\nplt.figure(figsize=(8, 5))\nplt.scatter(state_data['population'], state_data['num_sightings'], alpha=0.7, color='blue', s=40)\nplt.title(f'UFO Sightings vs Population in {chosen_state.upper()} (1950‚Äì2014)')\nplt.xlabel('Population')\nplt.ylabel('Number of Sightings')\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nimport pandas as pd\ndata = pd.read_csv(\"../data/complete.csv\", on_bad_lines='skip')\n\nC:\\Users\\anton\\AppData\\Local\\Temp\\ipykernel_96532\\793543894.py:2: DtypeWarning: Columns (5,9) have mixed types. Specify dtype option on import or set low_memory=False.\n  data = pd.read_csv(\"../data/complete.csv\", on_bad_lines='skip')"
  },
  {
    "objectID": "Explainer notebook/Explainernotebook.html",
    "href": "Explainer notebook/Explainernotebook.html",
    "title": "Motivation",
    "section": "",
    "text": "What is your dataset?\nThis project contains several datasets, in order to explore the phenomena of UFO sightings through multiple lenses. The first and main dataset is the NUFORC UFO Sightings dataset, sourced from the National UFO Reporting Center and hosted on Kaggle, comprises around 80,000 individual reports of unidentified flying object (UFO) sightings. These records span more than a century, offering a foundation for both quantitative and qualitative analysis of UFO sightings. The second dataset this project contains is covering US military bases, it contains 776 entries, and 10 attributes, describing the location, the name of the base and the branch of service which the base is tied to. The third and last dataset used, is a dataset over historic populations in the different US States.\nWhy did you choose this/these particular dataset(s)?\nThe interest in this dataset arises from a foundation of scientific curiosity. UFO sightings have long been a hot bed of conspiracy theory ranging from alleged extraterrestrial encounters to secret government projects. At the same time, they have played a prominent role in popular culture, featured in iconic films and television shows such as The X-Files, Close Encounters of the Third Kind, E.T., and The Thing, among many others. This makes the study of UFO reports not only intriguing but also culturally significant. We are particularly excited about the opportunity to explore these sightings through both quantitative and qualitative analysis. Regardless of whether one is a skeptic or a true believer, there is no denying the existence of UFOs in the strict sense of the term; Unidentified Flying Objects observed by individuals looking up at the sky. This dataset offers a substantial sample size spanning multiple decades and includes several key attributes that provide strong insights into these encounters. These include the reported shape of the object, geographic coordinates, state annotations, the duration of each sighting, and the year of occurrence. The militaray base dataset is interesting due to the coupling with government projects, such as air force experiemental flyings. The military base dataset is interesting because it is linked to government projects, such as experimental flights by the Air Force. The historic state population dataset, is interesting due to the correlation between popualtion and UFO sights.\nWhat was your goal for the end user‚Äôs experience?\nOur goal is to provide an engaging and informative experience that encourages critical thinking about UFO sightings. By taking a skeptical perspective, we aim to help users explore alternative explanations for sightings‚Äîsuch as proximity to military bases or population density. Through tools like heat maps and time series visualizations, we wanted users to interact with the data and uncover patterns that might suggest grounded, non-extraterrestrial causes for reported sightings.\n\nBasic Stats\nWrite about your choices in data cleaning and preprocessing\nFor the UFO sightings dataset, our first decision was to filter out all entries outside the United States. This choice was based on two main reasons. First, the vast majority of sightings approximately 74,000 out of 80,000 occurred within the U.S., making it the most relevant and data-rich region for analysis. Second, this allowed us to narrow the scope of the project to a more manageable and consistent geographic focus.\nIn the military base dataset, we further refined the data to include only U.S. Air Force bases. While all branches of the military operate aircraft, the Air Force is uniquely dedicated to aeronautics. Additionally, it would be difficult to reliably distinguish between different types of army bases (e.g., infantry vs.¬†air units), making the Air Force the most suitable focus for this analysis. We removed all rows containing missing (NaN) values from each dataset.\nWrite a short section that discusses the dataset stats, containing key points/plots from your exploratory data analysis A lot of the data does not any obvious dataset stats like median, mean or standard deviation. This is because its often things like states, coordinates, or dates of of reporting. Alot of the explorative data analysis came from the plots we ended up showing. Where as we just made the plots cleaner and interactive. An example could be the heat map. Where we just had to create the heat map in order to see if our hypothesis were correct. \nOne of the more explorative data analysis we did was with the hour of day plot which we did plot to see if there were anything of interest.\nFor population the interesting thing was not much nescessarily the population but the correlation between the population and the UFO sightings. The big plot which included all the datapoints about population and ufo sightings were actually also explorative since we wanted to see if there were anything interesting about the correlation.\n\n\n\nalt text\n\n\n\n\nData Analysis\nOur types of data analysis can be categorised into two categories. Trying to plot data from which we can see a trend or trying to find a correlation between data. We wanted to see if we could find a trend in the number of UFO sightings. We wanted to see if there was a trend in regards to airforce bases and we wanted to there was a trend of when the sightings happened. From this we got suspesison that there was a correlation between the number of UFO sightings and the population of the states. Which we then wanted to look further into by calclating the correlation coefficient.\nWe learned that the number of sightings have been increasing over the years and that some signinficant media releases might have had an impact on increasing the number of sightings. We did also find out that our hypothesis about airforce bases and UFO sightings might not have that correect and that the explanation might more so be because of the population of the different states and the fact that airforce bases are often located in more populated areas.\nWe did also find out that the most common shape of UFOs are light and that they are often reported in the evening. This is not surprising since most people are awake during the evening and that the light is more visible in the dark.\nWe did find out that there is a rather strong correaltion population and the number of UFO sightings.\n\n\nGenre. Which genre of data story did you use?\nThis project lends itself naturally to a magazine-style format. Instead of simply representing af straightforward narative, it showcases a collection of interconnected visualisations, therefore it would also require some explanatory text, inbetween the visiaulations in order to discuss their meaning and relation.\nVisual Narative\nFor visual structuring the project is structured using a consisten visual platform, it uses the same color scheme for all visualisations, through a consistent visual narrative.\nWhich tools did you use from each of the 3 categories of Narrative Structure (Figure 7 in Segal and Heer). Why?\nNarative structure\nThis project employed linear ordering. The layout follows a linear structure, guiding the reader from top to bottom. Each section pairs explanatory text with its corresponding plot, encouraging readers to read, reflect on the visualization, and then move naturally to the next insight in the sequence.\nThe project also used hover/highlighting in order to increase the information of each plot shown, for example in the correlation plots it is possible to observe which state, what year, and the number of sightings each datapoint represents. Using hover/highlighting it is possible to add this additional information without it adding more noise to the visualisation. Another interactivity method used was filetering, figure 5, allowing the reader to filter for states, in order to see correlation of a unique state.\nFor messaging the project used captions for captions and annotations for every visualisation in order to simplify for the reader the information of the visualisation. Thereby we expect the reader can extrapolate more information more efficiently from each visualisation. The project has an introduction in order to clue the reader in on what this project will investigate, but also the motivation behind the investigation. Additionally, the visualizations are accompanied by a written article that offers further explanation, background, and interpretation to enhance the overall narrative.\n\n\nVisualizations\nExplain the visualizations you‚Äôve chosen.\nWhy are they right for the story you want to tell?\n\n\nDiscussion. Think critically about your creation\nWhat went well?\nWe think that we extrapolated quite a lot of information from the UFO sightings data. By comparing sightings to movie releases, correlating state populations with sightings, applying a heatmap and marking USA airforce bases and likewise looking at the time of day of said sightings. We have been able to say a lot about the tendencies in the increases of sightings.\nWhat is still missing? What could be improved?, Why?\nFurther analysis into the data s.t. applying NLP (Natural Language Processing) to work with the comments people came with for their sightings. This would have opened a lot of doors, as the comments might have given some qualitative data that we cant just extrapolate from atributes such as date, location, shape etc.\nOne of the main problems is that we do not present anything 100% conclusive in the data. Since a lot of the data can be explained simply by the fact that the more people increase the number of sightings. Therefore it is hard to conclude anything in regards to things like airforce bases and hour of the day. It just also kinda difficult when working with social data to say anything simple. Since it often hugely complex why things like UFO sightings increase.\n\n\nContributions. Who did what?\nYou should write (just briefly) which group member was the main responsible for which elements of the assignment. (I want you guys to understand every part of the assignment, but usually there is someone who took lead role on certain portions of the work. That‚Äôs what you should explain). It is not OK simply to write ‚ÄúAll group members contributed equally‚Äù. Make sure that you use references when they‚Äôre needed and follow academic standards."
  }
]